{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from replay_memory import ReplayBuffer, PrioritizedReplayBuffer\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# 만약 opencv-python이 설치되어있지 않다면 다음을 통해서 설치해주세요.\n",
    "# pip install opencv-python\n",
    "# 만약 설치에 오류가 발생한다면 다음을 참고해주세요.\n",
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_setup/py_table_of_contents_setup/py_table_of_contents_setup.html#py-table-of-content-setup\n",
    "from wrappers import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "'''DQN settings'''\n",
    "# sequential images to define state\n",
    "STATE_LEN = 4\n",
    "# target policy sync interval\n",
    "TARGET_REPLACE_ITER = 1\n",
    "# simulator steps for start learning\n",
    "LEARN_START = 10**4\n",
    "# (prioritized) experience replay memory size\n",
    "MEMORY_CAPACITY = 10**6\n",
    "# simulator steps for learning interval\n",
    "LEARN_FREQ = 4\n",
    "# check per\n",
    "is_per = True\n",
    "# alpha of PER\n",
    "PER_ALPHA = 0.6\n",
    "PER_BETA = 0.4\n",
    "PER_EPSILON = 1e-6\n",
    "# Double DQN\n",
    "DOUBLE = True\n",
    "# Dueling architecture\n",
    "DUEL = True\n",
    "\n",
    "'''Environment Settings'''\n",
    "# openai gym env name\n",
    "ENV_NAME = 'PongNoFrameskip-v4'\n",
    "env = wrap(gym.make(ENV_NAME))\n",
    "N_ACTIONS = env.action_space.n\n",
    "N_STATES = env.observation_space.shape\n",
    "# Total simulation step\n",
    "STEP_NUM = 10**7\n",
    "# gamma for MDP\n",
    "GAMMA = 0.99\n",
    "# visualize for agent playing\n",
    "RENDERING = False\n",
    "\n",
    "'''Training settings'''\n",
    "# check GPU usage\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "print('USE GPU: '+str(USE_GPU))\n",
    "# mini-batch size\n",
    "BATCH_SIZE = 32\n",
    "# learning rage\n",
    "LR = 1e-4\n",
    "# epsilon-greedy\n",
    "EPSILON = 0.0\n",
    "\n",
    "'''Save&Load Settings'''\n",
    "# check save/load\n",
    "SAVE = True\n",
    "LOAD = False\n",
    "# save frequency\n",
    "SAVE_FREQ = 10**5\n",
    "# paths for predction net, target net, result log\n",
    "PRED_PATH = './data/model/pred_net.pkl'\n",
    "TARGET_PATH = './data/model/target_net.pkl'\n",
    "RESULT_PATH = './data/plots/result.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구조 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # nn.Sequential을 사용하면 다음과 같입 코드를 간결하게 바꿀 수 있습니다.\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(STATE_LEN, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 256)\n",
    "\n",
    "        if DUEL:\n",
    "            # advantage function/ state value function\n",
    "            self.fc_adv = nn.Linear(256, N_ACTIONS)\n",
    "            self.fc_val = nn.Linear(256, 1)\n",
    "        else:\n",
    "            # action value function\n",
    "            self.fc_q = nn.Linear(256, N_ACTIONS) \n",
    "            \n",
    "        # 파라미터 값 초기화 코드는 다음과 같이 간결하게 바꿀 수 있습니다.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x는 (m, 84, 84, 4)의 tensor\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        \n",
    "        if DUEL:\n",
    "            adv = self.fc_adv(x)\n",
    "            val = self.fc_val(x)\n",
    "            action_value = val + adv - adv.mean(1).unsqueeze(1)\n",
    "        else:\n",
    "            action_value = self.fc_q(x)\n",
    "\n",
    "        return action_value\n",
    "\n",
    "    def save(self, PATH):\n",
    "        torch.save(self.state_dict(),PATH)\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.pred_net, self.target_net = ConvNet(), ConvNet()\n",
    "        # sync eval target\n",
    "        self.update_target(self.target_net, self.pred_net, 1.0)\n",
    "        # use gpu\n",
    "        if USE_GPU:\n",
    "            self.pred_net.cuda()\n",
    "            self.target_net.cuda()\n",
    "            \n",
    "        # simulator step conter\n",
    "        self.memory_counter = 0\n",
    "        # target network step counter\n",
    "        self.learn_step_counter = 0\n",
    "        \n",
    "        # ceate the replay buffer\n",
    "        if is_per:\n",
    "            self.replay_buffer = PrioritizedReplayBuffer(MEMORY_CAPACITY, alpha=PER_ALPHA)\n",
    "        else:\n",
    "            self.replay_buffer = ReplayBuffer(MEMORY_CAPACITY)\n",
    "        \n",
    "        # define optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.pred_net.parameters(), lr=LR)\n",
    "        \n",
    "    def update_target(self, target, pred, update_rate):\n",
    "        # update target network parameters using predcition network\n",
    "        for target_param, pred_param in zip(target.parameters(), pred.parameters()):\n",
    "            target_param.data.copy_((1.0 - update_rate) \\\n",
    "                                    * target_param.data + update_rate*pred_param.data)\n",
    "            \n",
    "    def save_model(self):\n",
    "        # save prediction network and target network\n",
    "        self.pred_net.save(PRED_PATH)\n",
    "        self.target_net.save(TARGET_PATH)\n",
    "\n",
    "    def load_model(self):\n",
    "        # load prediction network and target network\n",
    "        self.pred_net.load(PRED_PATH)\n",
    "        self.target_net.load(TARGET_PATH)\n",
    "\n",
    "    def choose_action(self, x, EPSILON):\n",
    "        x = torch.FloatTensor(x)\n",
    "        if USE_GPU:\n",
    "            x = x.cuda()\n",
    "\n",
    "        if np.random.uniform() < EPSILON:\n",
    "            # greedy case\n",
    "            action_value = self.pred_net(x.unsqueeze(0))\n",
    "            action = torch.argmax(action_value).data.cpu().numpy()\n",
    "        else:\n",
    "            # random exploration case\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_, done):\n",
    "        self.memory_counter += 1\n",
    "        self.replay_buffer.add(s, a, r, s_, float(done))\n",
    "\n",
    "    def learn(self, beta):\n",
    "        self.learn_step_counter += 1\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.update_target(self.target_net, self.pred_net, 1e-2)\n",
    "        \n",
    "        # data sample from experience replay\n",
    "        if is_per:\n",
    "            experience = self.replay_buffer.sample(BATCH_SIZE, beta=beta)\n",
    "            (b_state_memory, b_action_memory, b_reward_memory, \\\n",
    "             b_next_state_memory, b_done, b_weights, b_idxes) = experience\n",
    "        else:\n",
    "            b_state_memory, b_action_memory, b_reward_memory, \\\n",
    "            b_next_state_memory, b_done = self.replay_buffer.sample(BATCH_SIZE)\n",
    "            b_weights, b_idxes = np.ones_like(b_reward_memory), None\n",
    "            \n",
    "        b_s = torch.FloatTensor(b_state_memory)\n",
    "        b_a = torch.LongTensor(b_action_memory)\n",
    "        b_r = torch.FloatTensor(b_reward_memory)\n",
    "        b_s_ = torch.FloatTensor(b_next_state_memory)\n",
    "        b_d = torch.FloatTensor(b_done)\n",
    "\n",
    "        if USE_GPU:\n",
    "            b_s, b_a, b_r, b_s_, b_d = b_s.cuda(), b_a.cuda(), b_r.cuda(), b_s_.cuda(), b_d.cuda()\n",
    "\n",
    "        # action value prediction\n",
    "        q_eval = self.pred_net(b_s).gather(1, b_a.unsqueeze(1)).view(-1)\n",
    "        # shape : (m)\n",
    "\n",
    "        if DOUBLE:\n",
    "            # get best actions of next state\n",
    "            _ , best_actions = self.pred_net(b_s_).detach().max(1)\n",
    "            # get next state value\n",
    "            q_next = self.target_net(b_s_).detach()\n",
    "            # get target value\n",
    "            q_target = b_r + GAMMA *(1.-b_d)* q_next.gather(1, best_actions.unsqueeze(1)).squeeze(1)\n",
    "            # shape (m)\n",
    "        else:\n",
    "            # get next state value\n",
    "            q_next = self.target_net(b_s_).detach()\n",
    "            # get target value\n",
    "            q_target = b_r + GAMMA *(1.-b_d)* q_next.max(1)[0]\n",
    "            # shape (m)\n",
    "            \n",
    "        # calc huber loss, dont reduce for importance weight\n",
    "        loss = F.smooth_l1_loss(q_eval, q_target, reduction='none')\n",
    "        # calc importance weighted loss\n",
    "        b_w = torch.Tensor(b_weights)\n",
    "        if USE_GPU:\n",
    "            b_w = b_w.cuda()\n",
    "        loss = torch.mean(b_w*loss)\n",
    "        # get td error\n",
    "        td_error = (q_target - q_eval).data.cpu().numpy()\n",
    "        \n",
    "        # update importance weight\n",
    "        if is_per:\n",
    "            new_priorities = np.abs(td_error) + PER_EPSILON\n",
    "            self.replay_buffer.update_priorities(b_idxes, new_priorities)\n",
    "        \n",
    "        # backprop loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.pred_net.parameters(),10.)\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize results!\n",
      "Collecting experience...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyub/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  109 | Mean ep 10 return:  -20.56 /Used Time: 354.13 /Used Step: 100000\n",
      "Save complete!\n",
      "Ep:  205 | Mean ep 10 return:  -19.89 /Used Time: 898.0 /Used Step: 200000\n",
      "Save complete!\n",
      "Ep:  292 | Mean ep 10 return:  -19.22 /Used Time: 1449.65 /Used Step: 300000\n",
      "Save complete!\n",
      "Ep:  373 | Mean ep 10 return:  -18.44 /Used Time: 2010.8 /Used Step: 400000\n",
      "Save complete!\n",
      "Ep:  445 | Mean ep 10 return:  -17.44 /Used Time: 2583.16 /Used Step: 500000\n",
      "Save complete!\n",
      "Ep:  507 | Mean ep 10 return:  -15.11 /Used Time: 3159.38 /Used Step: 600000\n",
      "Save complete!\n",
      "Ep:  556 | Mean ep 10 return:  -10.11 /Used Time: 3738.0 /Used Step: 700000\n",
      "Save complete!\n",
      "Ep:  603 | Mean ep 10 return:  -8.89 /Used Time: 4323.51 /Used Step: 800000\n",
      "Save complete!\n",
      "Ep:  646 | Mean ep 10 return:  -6.0 /Used Time: 4917.18 /Used Step: 900000\n",
      "Save complete!\n",
      "Ep:  684 | Mean ep 10 return:  7.33 /Used Time: 5516.89 /Used Step: 1000000\n",
      "Save complete!\n",
      "Ep:  726 | Mean ep 10 return:  6.22 /Used Time: 6120.94 /Used Step: 1100000\n",
      "Save complete!\n",
      "Ep:  770 | Mean ep 10 return:  11.56 /Used Time: 6731.67 /Used Step: 1200000\n",
      "Save complete!\n",
      "Ep:  815 | Mean ep 10 return:  12.67 /Used Time: 7340.7 /Used Step: 1300000\n",
      "Save complete!\n",
      "Ep:  859 | Mean ep 10 return:  12.56 /Used Time: 7954.64 /Used Step: 1400000\n",
      "Save complete!\n",
      "Ep:  904 | Mean ep 10 return:  13.44 /Used Time: 8562.6 /Used Step: 1500000\n",
      "Save complete!\n",
      "Ep:  951 | Mean ep 10 return:  15.11 /Used Time: 9186.89 /Used Step: 1600000\n",
      "Save complete!\n",
      "Ep:  997 | Mean ep 10 return:  13.0 /Used Time: 9796.29 /Used Step: 1700000\n",
      "Save complete!\n",
      "Ep:  1047 | Mean ep 10 return:  15.11 /Used Time: 10416.6 /Used Step: 1800000\n",
      "Save complete!\n",
      "Ep:  1095 | Mean ep 10 return:  14.89 /Used Time: 11039.66 /Used Step: 1900000\n",
      "Save complete!\n",
      "Ep:  1144 | Mean ep 10 return:  17.0 /Used Time: 11658.07 /Used Step: 2000000\n",
      "Save complete!\n",
      "Ep:  1195 | Mean ep 10 return:  17.56 /Used Time: 12266.2 /Used Step: 2100000\n",
      "Save complete!\n",
      "Ep:  1245 | Mean ep 10 return:  15.89 /Used Time: 12871.77 /Used Step: 2200000\n",
      "Save complete!\n",
      "Ep:  1294 | Mean ep 10 return:  14.22 /Used Time: 13477.5 /Used Step: 2300000\n",
      "Save complete!\n",
      "Ep:  1345 | Mean ep 10 return:  16.89 /Used Time: 14087.9 /Used Step: 2400000\n",
      "Save complete!\n",
      "Ep:  1395 | Mean ep 10 return:  16.11 /Used Time: 14695.45 /Used Step: 2500000\n",
      "Save complete!\n",
      "Ep:  1444 | Mean ep 10 return:  17.33 /Used Time: 15303.01 /Used Step: 2600000\n",
      "Save complete!\n",
      "Ep:  1493 | Mean ep 10 return:  16.11 /Used Time: 15910.93 /Used Step: 2700000\n",
      "Save complete!\n",
      "Ep:  1543 | Mean ep 10 return:  17.78 /Used Time: 16519.49 /Used Step: 2800000\n",
      "Save complete!\n",
      "Ep:  1592 | Mean ep 10 return:  15.89 /Used Time: 17128.03 /Used Step: 2900000\n",
      "Save complete!\n",
      "Ep:  1643 | Mean ep 10 return:  16.67 /Used Time: 17738.61 /Used Step: 3000000\n",
      "Save complete!\n",
      "Ep:  1696 | Mean ep 10 return:  18.67 /Used Time: 18356.92 /Used Step: 3100000\n",
      "Save complete!\n",
      "Ep:  1747 | Mean ep 10 return:  17.11 /Used Time: 18966.98 /Used Step: 3200000\n",
      "Save complete!\n",
      "Ep:  1799 | Mean ep 10 return:  17.0 /Used Time: 19574.44 /Used Step: 3300000\n",
      "Save complete!\n",
      "Ep:  1851 | Mean ep 10 return:  17.67 /Used Time: 20182.71 /Used Step: 3400000\n",
      "Save complete!\n",
      "Ep:  1902 | Mean ep 10 return:  17.56 /Used Time: 20790.85 /Used Step: 3500000\n",
      "Save complete!\n",
      "Ep:  1954 | Mean ep 10 return:  17.0 /Used Time: 21428.87 /Used Step: 3600000\n",
      "Save complete!\n",
      "Ep:  2004 | Mean ep 10 return:  16.89 /Used Time: 22041.73 /Used Step: 3700000\n",
      "Save complete!\n",
      "Ep:  2056 | Mean ep 10 return:  17.11 /Used Time: 22650.33 /Used Step: 3800000\n",
      "Save complete!\n",
      "Ep:  2109 | Mean ep 10 return:  17.33 /Used Time: 23257.99 /Used Step: 3900000\n",
      "Save complete!\n",
      "Ep:  2161 | Mean ep 10 return:  16.78 /Used Time: 23868.62 /Used Step: 4000000\n",
      "Save complete!\n",
      "Ep:  2213 | Mean ep 10 return:  17.0 /Used Time: 24476.58 /Used Step: 4100000\n",
      "Save complete!\n",
      "Ep:  2265 | Mean ep 10 return:  17.56 /Used Time: 25084.39 /Used Step: 4200000\n",
      "Save complete!\n",
      "Ep:  2317 | Mean ep 10 return:  18.11 /Used Time: 25691.78 /Used Step: 4300000\n",
      "Save complete!\n",
      "Ep:  2369 | Mean ep 10 return:  18.56 /Used Time: 26302.29 /Used Step: 4400000\n",
      "Save complete!\n",
      "Ep:  2421 | Mean ep 10 return:  18.33 /Used Time: 26913.31 /Used Step: 4500000\n",
      "Save complete!\n",
      "Ep:  2473 | Mean ep 10 return:  17.78 /Used Time: 27521.91 /Used Step: 4600000\n",
      "Save complete!\n",
      "Ep:  2524 | Mean ep 10 return:  18.11 /Used Time: 28129.22 /Used Step: 4700000\n",
      "Save complete!\n",
      "Ep:  2575 | Mean ep 10 return:  17.56 /Used Time: 28742.57 /Used Step: 4800000\n",
      "Save complete!\n",
      "Ep:  2629 | Mean ep 10 return:  18.22 /Used Time: 29350.65 /Used Step: 4900000\n",
      "Save complete!\n",
      "Ep:  2680 | Mean ep 10 return:  17.78 /Used Time: 29960.01 /Used Step: 5000000\n",
      "Save complete!\n",
      "Ep:  2734 | Mean ep 10 return:  18.0 /Used Time: 30568.85 /Used Step: 5100000\n",
      "Save complete!\n",
      "Ep:  2788 | Mean ep 10 return:  18.0 /Used Time: 31177.91 /Used Step: 5200000\n",
      "Save complete!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c69f5e6a3fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# if memory fill 50K and mod 4 = 0(for speed issue), learn pred net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5e+4\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_counter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mLEARN_FREQ\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPER_BETA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# print log and save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1b09698a8052>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, beta)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dqn = DQN()\n",
    "\n",
    "# model load with check\n",
    "if LOAD and os.path.isfile(PRED_PATH) and os.path.isfile(TARGET_PATH):\n",
    "    dqn.load_model()\n",
    "    pkl_file = open(RESULT_PATH,'rb')\n",
    "    result = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    print('Load complete!')\n",
    "else:\n",
    "    result = []\n",
    "    print('Initialize results!')\n",
    "\n",
    "print('Collecting experience...')\n",
    "\n",
    "# episode step for accumulate reward \n",
    "# (since we are using EpisodicLifeEnv of OpenAI gym wrapper)\n",
    "epi_step = 0\n",
    "# accumulate return of current episode\n",
    "entire_ep_r = 0.\n",
    "# log for accumulate returns\n",
    "entire_ep_rs = []\n",
    "# check learning time\n",
    "start_time = time.time()\n",
    "\n",
    "while dqn.memory_counter <= STEP_NUM:\n",
    "    # env reset\n",
    "    s = np.array(env.reset())\n",
    "    \n",
    "    # initialize one episode reward\n",
    "    ep_r = 0.\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(s, EPSILON)\n",
    "\n",
    "        # take action and get next state\n",
    "        s_, r, done, info = env.step(a)\n",
    "        s_ = np.array(s_)\n",
    "        \n",
    "        # accumulate return\n",
    "        ep_r += r\n",
    "        # clip rewards for numerical stability\n",
    "        clip_r = np.sign(r)\n",
    "\n",
    "        # store the transition\n",
    "        dqn.store_transition(s, a, clip_r, s_, float(done))\n",
    "\n",
    "        # annealing the epsilon(exploration strategy), beta(per smoothing)\n",
    "        if dqn.memory_counter <= MEMORY_CAPACITY:\n",
    "            # linear annealing to 0.9 until million step\n",
    "            EPSILON += 0.9/MEMORY_CAPACITY\n",
    "        elif dqn.memory_counter <= STEP_NUM:\n",
    "            # linear annealing to 0.99 until the end\n",
    "            EPSILON += 0.09/(STEP_NUM - MEMORY_CAPACITY)\n",
    "            # linear annealing to 1 until the end\n",
    "            PER_BETA += (1.0 - PER_BETA) /(STEP_NUM - MEMORY_CAPACITY)\n",
    "\n",
    "        # if memory fill 50K and mod 4 = 0(for speed issue), learn pred net\n",
    "        if (5e+4 <= dqn.memory_counter) and (dqn.memory_counter % LEARN_FREQ == 0):\n",
    "            dqn.learn(PER_BETA)\n",
    "            \n",
    "        # print log and save\n",
    "        if dqn.memory_counter % SAVE_FREQ == 0:\n",
    "            # check time interval\n",
    "            time_interval = round(time.time() - start_time, 2)\n",
    "            # calc mean return\n",
    "            mean_10_ep_return = round(np.mean(entire_ep_rs[-10:-1]),2)\n",
    "            result.append(mean_10_ep_return)\n",
    "            # print log\n",
    "            print('Ep: ',epi_step,\n",
    "                  '| Mean ep 10 return: ', mean_10_ep_return,\n",
    "                  '/Used Time:',time_interval,\n",
    "                  '/Used Step:',dqn.memory_counter)\n",
    "            # save model\n",
    "            dqn.save_model()\n",
    "            pkl_file = open(RESULT_PATH, 'wb')\n",
    "            pickle.dump(np.array(result), pkl_file)\n",
    "            pkl_file.close()\n",
    "            print('Save complete!')\n",
    "            \n",
    "        # if agent meets end-of-life, update return, acc return\n",
    "        if done:\n",
    "            entire_ep_r += ep_r\n",
    "            epi_step += 1\n",
    "            if epi_step % 1 == 0:\n",
    "                entire_ep_rs.append(entire_ep_r)\n",
    "                entire_ep_r = 0.\n",
    "            break\n",
    "\n",
    "        s = s_\n",
    "\n",
    "        if RENDERING:\n",
    "            env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(entire_ep_rs)), entire_ep_rs)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "        \n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=5)\n",
    "    anim.save('./pong_result.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward : 21.00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD+CAYAAACgNTAxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAA85JREFUeJzt3bFNW1EYgFEcMUE8QzaggZ4iYgV2iMQgSNmBFVAKemjYgBmcFZwuEhGIYH/2u88+p7OMzd98uu/CffZivV6fANv7MvUAcCjEBBExQURMEBETRMQEETFBREwQERNETqce4D0/v38d7mjG5cX5p1/z8Pi0g0mm93xz9amfP7u93+r1b73HFH78+r147zkrE0TEBBExQWTYPdMcvLUf2mRfNUcf7V+23VNt8h5TszJBREwQERNE7JnYyNz2M/tgZYKImCAiJojYM5EY4dzc1KxMEBETRMQEETFBxB8gtnAsh1r/x0f/xK0Pxo7IygQRMUFETBBZjPqVMiN+oAr4QBXYAzFBZNjLvNVqNeZgHLXlcukyD3ZNTBARE0TEBBExQURMEBETRMQEETFBZNgTEA66MiIHXWEPxAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBZLYxXd+9nFzfvUw9Bvw125hgNGKCiJggIiaInE49wKburr9NPQK8YmWCiJggMtvLPPjI883Vq8dnt/c7/X0HHdPlxfmrxw+PTxNNwjFwmQcRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUHkoG/B4Ljt+v6lfx10TO5fYp9c5kFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEkcV6vZ56hjetVqsxB+OoLZfLxXvPWZkgIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoLIsDcHwtxYmSAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoj8AeLCUNTq/tR2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = wrap(gym.make('PongNoFrameskip-v4'))\n",
    "s = np.array(env.reset())\n",
    "total_reward = 0\n",
    "frames = []\n",
    "\n",
    "dqn = DQN()\n",
    "dqn.load_model()\n",
    "\n",
    "for t in range(10000):\n",
    "    # Render into buffer. \n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    a = dqn.choose_action(s, 1.0)\n",
    "    # take action and get next state\n",
    "    s_, r, done, info = env.step(a)\n",
    "    s_ = np.array(s_)\n",
    "    total_reward += r\n",
    "    if done:\n",
    "        break\n",
    "    s = s_\n",
    "env.close()\n",
    "print('Total Reward : %.2f'%total_reward)\n",
    "display_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./pong_result.gif \"segment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
