{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "from wrappers import wrap, wrap_cover, SubprocVecEnv\n",
    "from runner import Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_ACTIONS :  4\n",
      "N_STATES :  (4, 84, 84)\n",
      "USE GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/5_Exploration_Techinques/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/5_Exploration_Techinques/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/5_Exploration_Techinques/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/5_Exploration_Techinques/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "'''PPO Settings'''\n",
    "TRAJ_LEN = 128\n",
    "N_OPT_EPOCHS = 10\n",
    "ENT_COEF = 1e-2\n",
    "CLIP_RANGE = 0.1\n",
    "LAMBDA = 0.95\n",
    "\n",
    "'''RND Settings'''\n",
    "# RND start step for input normalization\n",
    "RND_START = int(0)\n",
    "# Discount rate for intrinsic reward\n",
    "INT_GAMMA = 0.99\n",
    "\n",
    "'''Environment Settings'''\n",
    "# sequential images to define state\n",
    "STATE_LEN = 4\n",
    "# openai gym env name\n",
    "ENV_NAME = 'BreakoutNoFrameskip-v4'\n",
    "# number of environments for A2C\n",
    "N_ENVS = 4\n",
    "# define gym \n",
    "env = SubprocVecEnv([wrap_cover(ENV_NAME) for i in range(N_ENVS)])\n",
    "# check gym setting\n",
    "N_ACTIONS = env.action_space.n;print('N_ACTIONS : ',N_ACTIONS) #  6\n",
    "N_STATES = env.observation_space.shape;print('N_STATES : ',N_STATES) # (4, 84, 84)\n",
    "# Total simulation step\n",
    "N_STEP = int(1e+7)\n",
    "# gamma for MDP\n",
    "GAMMA = 0.9999\n",
    "# visualize for agent playing\n",
    "RENDERING = False\n",
    "\n",
    "'''Training settings'''\n",
    "# check GPU usage\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "print('USE GPU: '+str(USE_GPU))\n",
    "# mini-batch size\n",
    "BATCH_SIZE = 128\n",
    "# learning rage\n",
    "LR = 1e-4\n",
    "# clip gradient\n",
    "MAX_GRAD_NORM = 0.1\n",
    "# log optimization\n",
    "LOG_OPT = False\n",
    "\n",
    "'''Save&Load Settings'''\n",
    "# log frequency\n",
    "LOG_FREQ = 10\n",
    "# check save/load\n",
    "SAVE = True\n",
    "LOAD = False\n",
    "# paths for predction net, target net, result log\n",
    "NET_PATH = './data/model/ppo_net.pkl'\n",
    "PRED_PATH = './data/model/pred_net.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구조 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # architecture def\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(STATE_LEN, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        # actor\n",
    "        self.actor = nn.Linear(256, N_ACTIONS)\n",
    "        # extrinsic critic\n",
    "        self.critic = nn.Linear(256, 1)\n",
    "        # intrinsic critic\n",
    "        self.int_critic = nn.Linear(256, 1)\n",
    "            \n",
    "        # parameter initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a tensor of (m, 4, 84, 84)\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(F.relu(x))\n",
    "        x = self.fc2(F.relu(x))\n",
    "        # use log_softmax for numerical stability\n",
    "        action_log_prob = F.log_softmax(self.actor(F.relu(x)), dim=1)\n",
    "        state_value = self.critic(F.relu(x))\n",
    "        int_state_value = self.int_critic(F.relu(x))\n",
    "\n",
    "        return action_log_prob, state_value, int_state_value\n",
    "\n",
    "    def save(self, PATH):\n",
    "        torch.save(self.state_dict(),PATH)\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.load_state_dict(torch.load(PATH))\n",
    "        \n",
    "class RandomPredNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RandomPredNet, self).__init__()\n",
    "        # architecture def\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "            nn.LeakyReLU(negative_slope=2e-1),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.LeakyReLU(negative_slope=2e-1),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 256)\n",
    "        # one more layer than target network for enough capacity\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        # if you use feature normalization in RND, remove division by 255.0\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(F.leaky_relu(x, negative_slope=2e-1))\n",
    "        x = self.fc2(F.leaky_relu(x, negative_slope=2e-1))\n",
    "        return x\n",
    "    \n",
    "    def save(self, PATH):\n",
    "        torch.save(self.state_dict(),PATH)\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.load_state_dict(torch.load(PATH))\n",
    "        \n",
    "class RandomTargetNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RandomTargetNet, self).__init__()\n",
    "        # architecture def\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 256)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if you use feature normalization in RND, remove division by 255.0\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RND 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self):\n",
    "        self.net = ConvNet()\n",
    "        self.rand_target = RandomTargetNet()\n",
    "        self.rand_pred = RandomPredNet()\n",
    "        # use gpu\n",
    "        if USE_GPU:\n",
    "            self.net = self.net.cuda()\n",
    "            self.rand_target = self.rand_target.cuda()\n",
    "            self.rand_pred = self.rand_pred.cuda()\n",
    "            \n",
    "        # simulator step conter\n",
    "        self.memory_counter = 0\n",
    "        \n",
    "        # define optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=LR)\n",
    "        # define optimizer for predict network\n",
    "        self.rand_pred_opt = torch.optim.Adam(self.rand_pred.parameters(), lr=LR)\n",
    "        \n",
    "        # ppo clip range\n",
    "        self.clip_range = CLIP_RANGE\n",
    "        \n",
    "        # observation statistics for RND (if you use feature normalization in RND)\n",
    "        self.s_mu = None\n",
    "        self.s_sigma = None\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.net.cpu()\n",
    "        self.rand_pred.cpu()\n",
    "        \n",
    "        self.net.save(NET_PATH)\n",
    "        self.rand_pred.save(PRED_PATH)\n",
    "        if USE_GPU:\n",
    "            self.net.cuda()\n",
    "            self.rand_pred.cuda()\n",
    "            \n",
    "    def load_model(self):\n",
    "        self.net.cpu()\n",
    "        self.rand_pred.cpu()\n",
    "        \n",
    "        self.net.load(NET_PATH)\n",
    "        self.rand_pred.load(PRED_PATH)\n",
    "        if USE_GPU:\n",
    "            self.net.cuda()\n",
    "            self.rand_pred.cuda()\n",
    "        \n",
    "    def choose_action(self, x):\n",
    "        self.memory_counter += 1\n",
    "        # Assume that x is a np.array of shape (nenvs, 4, 84, 84)\n",
    "        x = torch.FloatTensor(x)\n",
    "        if USE_GPU:\n",
    "            x = x.cuda()\n",
    "        # get action log probs and state values\n",
    "        action_log_probs, state_values, int_state_values = self.net(x) # (nenvs, N_ACTIONS)\n",
    "        probs = F.softmax(action_log_probs, dim=1).data.cpu().numpy()\n",
    "        # sample actions\n",
    "        actions = np.array([np.random.choice(N_ACTIONS,p=probs[i]) for i in range(len(probs))])\n",
    "        # convert tensor to np.array\n",
    "        action_log_probs = action_log_probs.data.cpu().numpy()\n",
    "        state_values = state_values.squeeze(1).data.cpu().numpy()\n",
    "        int_state_values = int_state_values.squeeze(1).data.cpu().numpy()\n",
    "        # calc selected logprob\n",
    "        selected_log_probs = np.array([action_log_probs[i][actions[i]] for i in range(len(probs))])\n",
    "        return actions, state_values, int_state_values, selected_log_probs\n",
    "    \n",
    "    def r_int(self, s):\n",
    "        s = torch.FloatTensor(s)\n",
    "        # feature normalization part in RND\n",
    "        # get intrinsic reward\n",
    "#         r_input = list()\n",
    "#         for i in range(len(s)):\n",
    "#             r_input.append((s[i, -1] - self.s_mu)/(self.s_sigma + 1e-8))\n",
    "#         s = torch.clamp(torch.FloatTensor(r_input).unsqueeze(1), -5., 5.) # (N_ENVS, 1, 84, 84)\n",
    "        if USE_GPU:\n",
    "            s = s.cuda()\n",
    "        r_target = self.rand_target(s) # (N_ENVS, 256)\n",
    "        r_pred = self.rand_pred(s) # (N_ENVS, 256)\n",
    "        r_int = torch.mean(F.mse_loss(r_target, r_pred, reduction='none'), dim=1)\n",
    "        \n",
    "        return r_int.data.cpu().numpy()\n",
    "    \n",
    "    def learn_predict(self, s):\n",
    "        s = torch.FloatTensor(s)\n",
    "        # feature normalization part in RND\n",
    "        # RND pred net optimize\n",
    "#         r_input = list()\n",
    "#         for i in range(len(s)):\n",
    "#             r_input.append((obs[i, -1] - self.s_mu)/(self.s_sigma + 1e-8))\n",
    "#         s = torch.clamp(torch.FloatTensor(r_input).unsqueeze(1), -5., 5.) # (N_ENVS, 1, 84, 84)\n",
    "        if USE_GPU:\n",
    "            s = s.cuda()\n",
    "        s.requires_grad = True\n",
    "        r_target = self.rand_target(s) # (N_ENVS, 256)\n",
    "        r_pred = self.rand_pred(s) # (N_ENVS, 256)\n",
    "        r_int = torch.mean(F.mse_loss(r_pred, r_target, reduction='none'), dim=1)\n",
    "        # (N_ENVS)\n",
    "        # zero-centered gradient penalty for vanishing gradient problem. You can remove this part\n",
    "        # check https://arxiv.org/abs/1801.04406 for more information.\n",
    "        grad = autograd.grad(r_int, s, create_graph=True,\n",
    "                        grad_outputs=torch.ones_like(r_int),\n",
    "                        retain_graph=True, only_inputs=True)[0].view(len(s), -1)\n",
    "        grad = grad.norm(dim=1)\n",
    "        loss = r_int.mean() + 100.0 * ((grad)**2).mean()\n",
    "        \n",
    "        self.rand_pred_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.rand_pred.parameters(), MAX_GRAD_NORM)\n",
    "        self.rand_pred_opt.step()\n",
    "        return r_int.data.cpu().numpy()\n",
    "\n",
    "    def learn(self, obs, returns, int_returns, masks, actions, values, int_values,  selected_log_probs):\n",
    "        # np.array -> torch.Tensor\n",
    "        obs = torch.FloatTensor(obs) # (m, 4, 84, 84)\n",
    "        returns = torch.FloatTensor(returns) # (m)\n",
    "        int_returns = torch.FloatTensor(int_returns) # (m)\n",
    "        actions = torch.LongTensor(actions) # (m)\n",
    "        selected_log_probs = torch.FloatTensor(selected_log_probs) # (m)\n",
    "        values = torch.FloatTensor(values) # (m)\n",
    "        int_values = torch.FloatTensor(int_values) # (m)\n",
    "        if USE_GPU:\n",
    "            obs = obs.cuda()\n",
    "            returns = returns.cuda()\n",
    "            int_returns = int_returns.cuda()\n",
    "            actions = actions.cuda()\n",
    "            selected_log_probs = selected_log_probs.cuda()\n",
    "            values = values.cuda()\n",
    "            int_values = int_values.cuda()\n",
    "        \n",
    "        # get action log probs and state values\n",
    "        action_log_probs, state_values, int_state_values = self.net(obs)\n",
    "        # (m, N_ACTIONS), (m, 1)\n",
    "        \n",
    "        # calculate the advantages\n",
    "        # original RND\n",
    "#         advs = 2 * (returns - values) + (int_returns - int_values)\n",
    "        # only intrinsic motivation agent's advantage\n",
    "        advs = (int_returns - int_values)\n",
    "        advs = (advs - advs.mean())/(advs.std() + 1e-8)\n",
    "        \n",
    "        # calc probs\n",
    "        probs = F.softmax(action_log_probs, dim=1)\n",
    "        # (m, N_ACTIONS)\n",
    "        \n",
    "        # calc entropy loss\n",
    "        ent_loss = ENT_COEF *((action_log_probs * probs).sum(dim=1)).mean()\n",
    "        # (1)\n",
    "        \n",
    "        # calc log probs\n",
    "        cur_log_probs = action_log_probs.gather(1,actions.unsqueeze(1))\n",
    "        # cur : (m, 1)\n",
    "        ratio = torch.exp(cur_log_probs.squeeze(1)-selected_log_probs)\n",
    "        # (m)\n",
    "        \n",
    "        # actor loss\n",
    "        surr1 = ratio * advs # (m)\n",
    "        surr2 = torch.clamp(ratio, 1.0 - self.clip_range, 1.0 + self.clip_range)*advs # (m)\n",
    "        actor_loss = -torch.min(surr1, surr2).mean() # (1)\n",
    "        # critic loss\n",
    "        critic_loss = F.smooth_l1_loss(state_values.squeeze(1), returns) # (1)\n",
    "        # int critic loss\n",
    "        int_critic_loss = F.smooth_l1_loss(int_state_values.squeeze(1), int_returns) # (1)\n",
    "\n",
    "        loss = actor_loss + critic_loss + ent_loss + int_critic_loss # (1)\n",
    "        \n",
    "        actor_loss, critic_loss, ent_loss, total_loss = actor_loss.data.cpu().numpy(), \\\n",
    "        critic_loss.data.cpu().numpy(), ent_loss.data.cpu().numpy(), loss.data.cpu().numpy()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.net.parameters(), MAX_GRAD_NORM)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return round(float(actor_loss), 4), round(float(critic_loss), 4),\\\n",
    "    round(float(ent_loss), 4), round(float(total_loss), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize results!\n",
      "Collecting experience...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/19531 [00:17<9:18:23,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  10 | Return mean:  8.05 | R_int_mean :  0.046 | R_int_std :  0.006 | Values :  0.421 | Int_values :  3.121 | Time: 17.17 | Used Step: 5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/19531 [00:33<8:35:40,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  20 | Return mean:  8.0 | R_int_mean :  0.077 | R_int_std :  0.009 | Values :  0.453 | Int_values :  1.718 | Time: 33.72 | Used Step: 10400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/19531 [00:49<8:27:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  30 | Return mean:  8.47 | R_int_mean :  0.082 | R_int_std :  0.011 | Values :  0.582 | Int_values :  1.887 | Time: 49.3 | Used Step: 15600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/19531 [01:05<8:26:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  40 | Return mean:  8.86 | R_int_mean :  0.076 | R_int_std :  0.01 | Values :  0.619 | Int_values :  1.729 | Time: 65.97 | Used Step: 20800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/19531 [01:22<9:09:16,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  50 | Return mean:  8.88 | R_int_mean :  0.078 | R_int_std :  0.01 | Values :  0.587 | Int_values :  2.096 | Time: 82.32 | Used Step: 26000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60/19531 [01:38<9:09:11,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  60 | Return mean:  9.07 | R_int_mean :  0.067 | R_int_std :  0.009 | Values :  0.877 | Int_values :  2.457 | Time: 98.73 | Used Step: 31200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 70/19531 [01:55<9:26:36,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  70 | Return mean:  9.54 | R_int_mean :  0.075 | R_int_std :  0.009 | Values :  0.774 | Int_values :  1.934 | Time: 115.72 | Used Step: 36400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 80/19531 [02:12<8:59:48,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  80 | Return mean:  9.0 | R_int_mean :  0.066 | R_int_std :  0.008 | Values :  0.6 | Int_values :  1.915 | Time: 132.0 | Used Step: 41600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 90/19531 [02:29<8:42:02,  1.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  90 | Return mean:  8.07 | R_int_mean :  0.093 | R_int_std :  0.012 | Values :  0.461 | Int_values :  1.925 | Time: 149.21 | Used Step: 46800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/19531 [02:46<8:59:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  100 | Return mean:  7.95 | R_int_mean :  0.083 | R_int_std :  0.011 | Values :  0.699 | Int_values :  1.938 | Time: 166.31 | Used Step: 52000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 110/19531 [03:02<8:57:21,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  110 | Return mean:  8.08 | R_int_mean :  0.073 | R_int_std :  0.009 | Values :  0.925 | Int_values :  2.128 | Time: 182.58 | Used Step: 57200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 120/19531 [03:18<8:49:58,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  120 | Return mean:  8.45 | R_int_mean :  0.076 | R_int_std :  0.01 | Values :  0.84 | Int_values :  2.018 | Time: 198.75 | Used Step: 62400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 130/19531 [03:35<9:05:49,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  130 | Return mean:  8.41 | R_int_mean :  0.074 | R_int_std :  0.01 | Values :  0.839 | Int_values :  2.152 | Time: 215.28 | Used Step: 67600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 140/19531 [03:51<8:26:35,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  140 | Return mean:  8.72 | R_int_mean :  0.061 | R_int_std :  0.007 | Values :  0.832 | Int_values :  2.244 | Time: 231.25 | Used Step: 72800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 150/19531 [04:07<8:30:13,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  150 | Return mean:  9.53 | R_int_mean :  0.064 | R_int_std :  0.008 | Values :  0.655 | Int_values :  2.095 | Time: 247.61 | Used Step: 78000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 160/19531 [04:25<9:26:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  160 | Return mean:  10.14 | R_int_mean :  0.072 | R_int_std :  0.009 | Values :  0.637 | Int_values :  2.186 | Time: 265.0 | Used Step: 83200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 170/19531 [04:41<8:44:30,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  170 | Return mean:  10.25 | R_int_mean :  0.065 | R_int_std :  0.008 | Values :  0.582 | Int_values :  1.659 | Time: 281.19 | Used Step: 88400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 180/19531 [04:59<9:56:27,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  180 | Return mean:  10.23 | R_int_mean :  0.078 | R_int_std :  0.01 | Values :  0.872 | Int_values :  2.274 | Time: 299.08 | Used Step: 93600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 190/19531 [05:15<8:26:49,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  190 | Return mean:  10.0 | R_int_mean :  0.064 | R_int_std :  0.009 | Values :  0.933 | Int_values :  2.449 | Time: 315.8 | Used Step: 98800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 200/19531 [05:32<8:28:56,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  200 | Return mean:  9.89 | R_int_mean :  0.082 | R_int_std :  0.011 | Values :  0.713 | Int_values :  1.759 | Time: 332.15 | Used Step: 104000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 210/19531 [05:49<9:42:27,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  210 | Return mean:  9.8 | R_int_mean :  0.084 | R_int_std :  0.011 | Values :  0.876 | Int_values :  2.583 | Time: 349.18 | Used Step: 109200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 220/19531 [06:05<8:18:34,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  220 | Return mean:  9.95 | R_int_mean :  0.076 | R_int_std :  0.009 | Values :  0.721 | Int_values :  1.633 | Time: 365.54 | Used Step: 114400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 230/19531 [06:22<9:01:06,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  230 | Return mean:  9.92 | R_int_mean :  0.078 | R_int_std :  0.01 | Values :  0.82 | Int_values :  2.287 | Time: 382.68 | Used Step: 119600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 240/19531 [06:39<8:36:26,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  240 | Return mean:  9.8 | R_int_mean :  0.067 | R_int_std :  0.008 | Values :  0.855 | Int_values :  2.032 | Time: 399.39 | Used Step: 124800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 250/19531 [06:56<9:15:52,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  250 | Return mean:  9.64 | R_int_mean :  0.061 | R_int_std :  0.008 | Values :  0.878 | Int_values :  2.115 | Time: 416.08 | Used Step: 130000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 260/19531 [07:13<9:07:09,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  260 | Return mean:  9.8 | R_int_mean :  0.065 | R_int_std :  0.009 | Values :  1.109 | Int_values :  2.063 | Time: 433.11 | Used Step: 135200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 270/19531 [07:29<8:37:06,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  270 | Return mean:  9.89 | R_int_mean :  0.08 | R_int_std :  0.011 | Values :  0.758 | Int_values :  1.729 | Time: 449.15 | Used Step: 140400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 280/19531 [07:47<9:53:11,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  280 | Return mean:  10.34 | R_int_mean :  0.059 | R_int_std :  0.008 | Values :  0.949 | Int_values :  2.119 | Time: 467.33 | Used Step: 145600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 290/19531 [08:04<9:07:28,  1.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  290 | Return mean:  9.97 | R_int_mean :  0.077 | R_int_std :  0.01 | Values :  0.49 | Int_values :  1.837 | Time: 484.7 | Used Step: 150800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 300/19531 [08:21<9:13:34,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  300 | Return mean:  9.78 | R_int_mean :  0.053 | R_int_std :  0.007 | Values :  1.605 | Int_values :  2.79 | Time: 501.95 | Used Step: 156000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 310/19531 [08:38<8:34:55,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  310 | Return mean:  9.57 | R_int_mean :  0.09 | R_int_std :  0.012 | Values :  0.842 | Int_values :  1.933 | Time: 518.91 | Used Step: 161200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 320/19531 [08:55<8:51:12,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  320 | Return mean:  9.46 | R_int_mean :  0.06 | R_int_std :  0.008 | Values :  0.938 | Int_values :  1.672 | Time: 535.53 | Used Step: 166400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 330/19531 [09:11<8:24:19,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  330 | Return mean:  9.04 | R_int_mean :  0.063 | R_int_std :  0.008 | Values :  1.064 | Int_values :  2.289 | Time: 551.6 | Used Step: 171600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 340/19531 [09:29<9:23:57,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  340 | Return mean:  8.97 | R_int_mean :  0.082 | R_int_std :  0.011 | Values :  0.854 | Int_values :  2.041 | Time: 569.08 | Used Step: 176800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 350/19531 [09:45<9:11:45,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  350 | Return mean:  8.89 | R_int_mean :  0.059 | R_int_std :  0.007 | Values :  0.628 | Int_values :  1.993 | Time: 585.58 | Used Step: 182000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 360/19531 [10:03<9:15:42,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  360 | Return mean:  8.91 | R_int_mean :  0.064 | R_int_std :  0.008 | Values :  1.069 | Int_values :  2.198 | Time: 603.42 | Used Step: 187200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 370/19531 [10:20<8:53:26,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  370 | Return mean:  8.89 | R_int_mean :  0.058 | R_int_std :  0.008 | Values :  1.428 | Int_values :  2.906 | Time: 620.23 | Used Step: 192400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 380/19531 [10:37<9:11:40,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  380 | Return mean:  8.96 | R_int_mean :  0.056 | R_int_std :  0.007 | Values :  1.028 | Int_values :  1.928 | Time: 637.14 | Used Step: 197600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 390/19531 [10:53<8:28:12,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  390 | Return mean:  9.09 | R_int_mean :  0.069 | R_int_std :  0.01 | Values :  1.118 | Int_values :  2.441 | Time: 653.06 | Used Step: 202800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 400/19531 [11:10<8:53:02,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  400 | Return mean:  9.08 | R_int_mean :  0.059 | R_int_std :  0.008 | Values :  1.31 | Int_values :  2.608 | Time: 670.22 | Used Step: 208000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 410/19531 [11:27<9:07:45,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  410 | Return mean:  9.35 | R_int_mean :  0.05 | R_int_std :  0.006 | Values :  1.566 | Int_values :  2.809 | Time: 687.75 | Used Step: 213200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 420/19531 [11:44<8:54:02,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  420 | Return mean:  9.3 | R_int_mean :  0.063 | R_int_std :  0.008 | Values :  1.297 | Int_values :  2.433 | Time: 704.29 | Used Step: 218400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 430/19531 [12:00<8:55:47,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  430 | Return mean:  9.51 | R_int_mean :  0.054 | R_int_std :  0.007 | Values :  1.452 | Int_values :  2.73 | Time: 720.42 | Used Step: 223600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 440/19531 [12:16<8:27:58,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  440 | Return mean:  9.67 | R_int_mean :  0.08 | R_int_std :  0.01 | Values :  0.94 | Int_values :  2.325 | Time: 736.52 | Used Step: 228800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 450/19531 [12:32<8:34:49,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  450 | Return mean:  9.97 | R_int_mean :  0.07 | R_int_std :  0.01 | Values :  1.727 | Int_values :  3.07 | Time: 752.63 | Used Step: 234000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 460/19531 [12:48<8:46:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  460 | Return mean:  9.98 | R_int_mean :  0.059 | R_int_std :  0.008 | Values :  1.013 | Int_values :  2.204 | Time: 768.96 | Used Step: 239200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 470/19531 [13:05<8:51:56,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  470 | Return mean:  10.05 | R_int_mean :  0.062 | R_int_std :  0.008 | Values :  1.196 | Int_values :  2.852 | Time: 785.75 | Used Step: 244400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 480/19531 [13:22<8:53:13,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  480 | Return mean:  10.15 | R_int_mean :  0.062 | R_int_std :  0.008 | Values :  1.29 | Int_values :  2.856 | Time: 802.53 | Used Step: 249600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 490/19531 [13:38<8:31:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  490 | Return mean:  10.12 | R_int_mean :  0.06 | R_int_std :  0.008 | Values :  0.998 | Int_values :  2.193 | Time: 818.66 | Used Step: 254800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 500/19531 [13:54<8:06:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  500 | Return mean:  10.07 | R_int_mean :  0.075 | R_int_std :  0.009 | Values :  0.612 | Int_values :  1.576 | Time: 834.66 | Used Step: 260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 510/19531 [14:12<9:15:59,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  510 | Return mean:  9.81 | R_int_mean :  0.067 | R_int_std :  0.009 | Values :  1.016 | Int_values :  2.084 | Time: 852.22 | Used Step: 265200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 520/19531 [14:29<9:28:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  520 | Return mean:  9.76 | R_int_mean :  0.05 | R_int_std :  0.006 | Values :  1.165 | Int_values :  3.124 | Time: 869.43 | Used Step: 270400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 530/19531 [14:45<8:50:58,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  530 | Return mean:  9.65 | R_int_mean :  0.05 | R_int_std :  0.006 | Values :  1.775 | Int_values :  3.201 | Time: 885.51 | Used Step: 275600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 540/19531 [15:02<9:02:24,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  540 | Return mean:  9.42 | R_int_mean :  0.066 | R_int_std :  0.008 | Values :  1.589 | Int_values :  2.711 | Time: 902.03 | Used Step: 280800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 550/19531 [15:19<8:42:24,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  550 | Return mean:  9.53 | R_int_mean :  0.063 | R_int_std :  0.008 | Values :  1.828 | Int_values :  2.904 | Time: 919.07 | Used Step: 286000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 560/19531 [15:34<8:36:36,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  560 | Return mean:  9.59 | R_int_mean :  0.073 | R_int_std :  0.009 | Values :  1.139 | Int_values :  2.187 | Time: 934.88 | Used Step: 291200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 570/19531 [15:51<8:28:30,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  570 | Return mean:  9.45 | R_int_mean :  0.062 | R_int_std :  0.008 | Values :  1.034 | Int_values :  2.259 | Time: 951.36 | Used Step: 296400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 580/19531 [16:06<7:53:41,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  580 | Return mean:  9.18 | R_int_mean :  0.066 | R_int_std :  0.009 | Values :  0.867 | Int_values :  2.199 | Time: 966.78 | Used Step: 301600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 590/19531 [16:23<8:19:44,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  590 | Return mean:  9.15 | R_int_mean :  0.067 | R_int_std :  0.009 | Values :  1.309 | Int_values :  2.798 | Time: 983.57 | Used Step: 306800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 600/19531 [16:40<8:35:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N :  600 | Return mean:  8.98 | R_int_mean :  0.049 | R_int_std :  0.006 | Values :  1.835 | Int_values :  3.202 | Time: 1000.46 | Used Step: 312000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 607/19531 [16:52<9:00:25,  1.71s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-923e9f863298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnupdates\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# get minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepinfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mepinfobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepinfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Deep_RL_with_pytorch/5_Exploration_Techinques/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Given observations, get action value and neglopacs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# We already have self.obs because Runner superclass run self.obs[:] = env.reset() on init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mmb_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mmb_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c49f6f8410d6>\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# sample actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_ACTIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# convert tensor to np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0maction_log_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_log_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c49f6f8410d6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# sample actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_ACTIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# convert tensor to np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0maction_log_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_log_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo = PPO()\n",
    "runner = Runner(env=env, model=ppo, nsteps=TRAJ_LEN, gamma=GAMMA, int_gamma=INT_GAMMA, lam=LAMBDA, rnd_start=RND_START)\n",
    "\n",
    "# model load with check\n",
    "if LOAD and os.path.isfile(PRED_PATH) and os.path.isfile(TARGET_PATH):\n",
    "    ppo.load_model()\n",
    "    pkl_file = open(RESULT_PATH,'rb')\n",
    "    result = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    print('Load complete!')\n",
    "else:\n",
    "    result = []\n",
    "    print('Initialize results!')\n",
    "\n",
    "print('Collecting experience...')\n",
    "\n",
    "# episode step for accumulate reward \n",
    "epinfobuf = deque(maxlen=100)\n",
    "# in PPO, we iterate over optimization step\n",
    "nbatch = N_ENVS * TRAJ_LEN\n",
    "nupdates = N_STEP// nbatch\n",
    "# check learning time\n",
    "start_time = time.time()\n",
    "\n",
    "for update in tqdm(range(1, nupdates+1)):\n",
    "    # get minibatch\n",
    "    obs, returns, int_rewards, int_returns, masks, actions, values, int_values, neglogpacs, epinfos = runner.run()\n",
    "    epinfobuf.extend(epinfos)\n",
    "    \n",
    "    if ppo.memory_counter > RND_START:\n",
    "        # calculate loss\n",
    "        inds = np.arange(nbatch)\n",
    "        for _ in range(N_OPT_EPOCHS):\n",
    "            a_losses, c_losses, e_losses, t_losses = list(), list(), list(), list()\n",
    "            # shuffle indices for i.i.d.\n",
    "            np.random.shuffle(inds)\n",
    "            # 0 to batch_size with batch_train_size step\n",
    "            for start in range(0, nbatch, BATCH_SIZE):\n",
    "                end = start + BATCH_SIZE\n",
    "                mbinds = inds[start:end]\n",
    "                slices = (arr[mbinds] for arr in (obs, returns, int_returns, masks, actions, values, int_values, neglogpacs))\n",
    "                actor_loss, critic_loss, ent_loss, total_loss = ppo.learn(*slices)\n",
    "                if np.random.rand() <= 0.25:\n",
    "                    ppo.learn_predict(obs[mbinds])\n",
    "            \n",
    "        if update % LOG_FREQ == 0:\n",
    "            # print log and save\n",
    "            # check time interval\n",
    "            time_interval = round(time.time() - start_time, 2)\n",
    "            # calc mean return\n",
    "            mean_100_ep_return = round(np.mean([epinfo['r'] for epinfo in epinfobuf]),2)\n",
    "            result.append(mean_100_ep_return)\n",
    "            # print epi log\n",
    "            print('N : ',update,\n",
    "                  '| Return mean: ', mean_100_ep_return,\n",
    "                  '| R_int_mean : ', round(np.mean(int_rewards),3),\n",
    "                  '| R_int_std : ', round(np.std(int_rewards),3),\n",
    "                  '| Values : ', round(np.mean(values), 3),\n",
    "                  '| Int_values : ', round(np.mean(int_values), 3),\n",
    "                  '| Time:',time_interval,\n",
    "                  '| Used Step:',ppo.memory_counter*N_ENVS)\n",
    "            # save model\n",
    "            if SAVE:\n",
    "                ppo.save_model()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(result)), result)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "        \n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=5)\n",
    "    anim.save('./rnd_breakout_result.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = wrap(gym.make('BreakoutNoFrameskip-v4'))\n",
    "s = np.array(env.reset())\n",
    "total_reward = 0\n",
    "frames = []\n",
    "done_counter = 0\n",
    "\n",
    "for t in range(10000):\n",
    "    # Render into buffer. \n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    a, v, int_v, l = ppo.choose_action(np.expand_dims(s,axis=0))\n",
    "    # take action and get next state\n",
    "    s_, r, done, info = env.step(a)\n",
    "    s_ = np.array(s_)\n",
    "    total_reward += r\n",
    "    if done:\n",
    "        done_counter += 1\n",
    "        if done_counter == 5:\n",
    "            break\n",
    "    s = s_\n",
    "env.close()\n",
    "print('Total Reward : %.2f'%total_reward)\n",
    "display_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./rnd_breakout_result.gif \"segment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
