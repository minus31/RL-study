{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import deque\n",
    "from replay_memory import ReplayBuffer, SilPrioritizedReplayBuffer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "from wrappers import wrap, wrap_cover, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_ACTIONS :  4\n",
      "N_STATES :  (4, 84, 84)\n",
      "USE GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: <class 'wrappers.FrameStack'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Process Process-16:\n",
      "Process Process-9:\n",
      "Process Process-14:\n",
      "Process Process-13:\n",
      "Process Process-15:\n",
      "Process Process-10:\n",
      "Process Process-6:\n",
      "Process Process-12:\n",
      "Process Process-8:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Process Process-11:\n",
      "Process Process-4:\n",
      "Process Process-5:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/Dropbox/Deep_RL_with_pytorch/4_Off-policy_Policy_Based_Methods/wrappers.py\", line 270, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sungyubkim/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "'''SAC Settings'''\n",
    "# coefficient of entropy regularization\n",
    "ENT_COEF = 1e-2\n",
    "# experience replay memory size\n",
    "MEMORY_CAPACITY = int(5e+5)\n",
    "# learn start\n",
    "LEARN_START = int(1e+3)\n",
    "# learn frequency\n",
    "LEARN_FREQ = 1\n",
    "\n",
    "'''Environment Settings'''\n",
    "# sequential images to define state\n",
    "STATE_LEN = 4\n",
    "# openai gym env name\n",
    "ENV_NAME = 'BreakoutNoFrameskip-v4'\n",
    "# number of environments for SAC\n",
    "N_ENVS = 4\n",
    "# define gym \n",
    "env = SubprocVecEnv([wrap_cover(ENV_NAME) for i in range(N_ENVS)])\n",
    "# check gym setting\n",
    "N_ACTIONS = env.action_space.n;print('N_ACTIONS : ',N_ACTIONS) #  4\n",
    "N_STATES = env.observation_space.shape;print('N_STATES : ',N_STATES) # (4, 84, 84)\n",
    "# Total simulation step\n",
    "N_STEP = 10**7\n",
    "# gamma for MDP\n",
    "GAMMA = 0.99\n",
    "# visualize for agent playing\n",
    "RENDERING = False\n",
    "\n",
    "'''Training settings'''\n",
    "# check GPU usage\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "print('USE GPU: '+str(USE_GPU))\n",
    "# mini-batch size\n",
    "BATCH_SIZE = 32\n",
    "# learning rage\n",
    "LR = 1e-4\n",
    "# clip gradient\n",
    "MAX_GRAD_NORM = 0.1\n",
    "\n",
    "'''Save&Load Settings'''\n",
    "# log frequency\n",
    "LOG_FREQ = int(1e+3)\n",
    "# check save/load\n",
    "SAVE = True\n",
    "LOAD = False\n",
    "# paths for predction net, target net, result log\n",
    "ACTOR_PATH = './data/model/sil_actor_net.pkl'\n",
    "CRITIC_PATH = './data/model/sil_critic_net.pkl'\n",
    "ACTION_CRITIC_PATH = './data/model/sil_action_critic_net.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구조 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorConvNet, self).__init__()\n",
    "        # architecture def\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(STATE_LEN, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 512)\n",
    "        # actor\n",
    "        self.actor = nn.Linear(512, N_ACTIONS)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a tensor of (m, 4, 84, 84)\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        # use log_softmax for numerical stability\n",
    "        action_log_prob = F.log_softmax(self.actor(x), dim=1)\n",
    "\n",
    "        return action_log_prob\n",
    "\n",
    "    def save(self, PATH):\n",
    "        torch.save(self.state_dict(),ACTOR_PATH)\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.load_state_dict(torch.load(ACTOR_PATH))\n",
    "        \n",
    "class CriticConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CriticConvNet, self).__init__()\n",
    "        # architecture def\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(STATE_LEN, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 512)\n",
    "        # actor\n",
    "        self.critic = nn.Linear(512, 1)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a tensor of (m, 4, 84, 84)\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        # use log_softmax for numerical stability\n",
    "        value = self.critic(x)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def save(self, PATH):\n",
    "        torch.save(self.state_dict(),CRITIC_PATH)\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.load_state_dict(torch.load(CRITIC_PATH))\n",
    "        \n",
    "class ActionCriticConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActionCriticConvNet, self).__init__()\n",
    "        # architecture def\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(STATE_LEN, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 512)\n",
    "        # actor\n",
    "        self.action_critic = nn.Linear(512, N_ACTIONS)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain = np.sqrt(2))\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a tensor of (m, 4, 84, 84)\n",
    "        x = self.feature_extraction(x / 255.0)\n",
    "        # x.size(0) : mini-batch size\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        # use log_softmax for numerical stability\n",
    "        action_value = self.action_critic(x)\n",
    "\n",
    "        return action_value\n",
    "\n",
    "    def save(self, PATH):\n",
    "        torch.save(self.state_dict(),ACTION_CRITIC_PATH)\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.load_state_dict(torch.load(ACTION_CRITIC_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of this code is based on original SIL code \n",
    "# https://github.com/junhyukoh/self-imitation-learning/blob/master/baselines/common/self_imitation.py\n",
    "class SSAC:\n",
    "    def __init__(self):\n",
    "        self.actor_net = ActorConvNet()\n",
    "        self.critic_net = CriticConvNet()\n",
    "        self.critic_target = CriticConvNet()\n",
    "        self.action_critic_net = ActionCriticConvNet()\n",
    "        # use gpu\n",
    "        if USE_GPU:\n",
    "            self.actor_net = self.actor_net.cuda()\n",
    "            self.critic_net = self.critic_net.cuda()\n",
    "            # critic target network for stability\n",
    "            self.critic_target = self.critic_net.cuda()\n",
    "            self.action_critic_net = self.action_critic_net.cuda()\n",
    "        \n",
    "        # sync net and target\n",
    "        self.critic_target.load_state_dict(self.critic_net.state_dict())\n",
    "            \n",
    "        # simulator step conter\n",
    "        self.memory_counter = 0\n",
    "        self.learn_step_counter = 0\n",
    "        \n",
    "        # create running episode memory\n",
    "        self.running_episodes = [[] for _ in range(N_ENVS)]\n",
    "        \n",
    "        # Create the replay buffer\n",
    "        self.replay_buffer = ReplayBuffer(MEMORY_CAPACITY)\n",
    "        self.sil_buffer = SilPrioritizedReplayBuffer(MEMORY_CAPACITY, 0.6)\n",
    "            \n",
    "        # define optimizer\n",
    "        self.actor_opt = torch.optim.Adam(self.actor_net.parameters(), lr=LR)\n",
    "        self.critic_opt = torch.optim.Adam(self.critic_net.parameters(), lr=LR)\n",
    "        self.action_critic_opt = torch.optim.Adam(self.action_critic_net.parameters(), lr=LR)\n",
    "        \n",
    "    def update_target(self, target, pred, update_rate):\n",
    "        # update target network parameters using predcition network\n",
    "        for target_param, pred_param in zip(target.parameters(), pred.parameters()):\n",
    "            target_param.data.copy_((1.0 - update_rate) \\\n",
    "                                    * target_param.data + update_rate*pred_param.data)\n",
    "        \n",
    "    def save_model(self):\n",
    "        self.actor_net.cpu()\n",
    "        self.critic_net.cpu()\n",
    "        self.action_critic_net.cpu()\n",
    "        \n",
    "        self.actor_net.save(ACTOR_PATH)\n",
    "        self.critic_net.save(CRITIC_PATH)\n",
    "        self.action_critic_net.save(ACTION_CRITIC_PATH)\n",
    "        \n",
    "        if USE_GPU:\n",
    "            self.actor_net.cuda()\n",
    "            self.critic_net.cuda()\n",
    "            self.action_critic_net.cuda()\n",
    "            \n",
    "    def load_model(self):\n",
    "        self.actor_net.cpu()\n",
    "        self.critic_net.cpu()\n",
    "        self.action_critic_net.cpu()\n",
    "        \n",
    "        self.actor_net.load(ACTOR_PATH)\n",
    "        self.critic_net.load(CRITIC_PATH)\n",
    "        self.action_critic_net.load(ACTION_CRITIC_PATH)\n",
    "        \n",
    "        if USE_GPU:\n",
    "            self.actor_net.cuda()\n",
    "            self.critic_net.cuda()\n",
    "            self.action_critic_net.cuda()\n",
    "        \n",
    "    def choose_action(self, x):\n",
    "        # Assume that x is a np.array of shape (nenvs, 4, 84, 84)\n",
    "        x = torch.FloatTensor(x)\n",
    "        if USE_GPU:\n",
    "            x = x.cuda()\n",
    "        # get action log probs and state values\n",
    "        action_log_prob = self.actor_net(x)\n",
    "        action_prob = F.softmax(action_log_prob, dim=1).data.cpu().numpy()\n",
    "        # sample actions\n",
    "        action = np.array([np.random.choice(N_ACTIONS,p=action_prob[i]) for i in range(len(action_prob))])\n",
    "        return action\n",
    "    \n",
    "    def store_transition(self, s, a, r, s_, done):\n",
    "        self.memory_counter += 1\n",
    "        self.replay_buffer.add(s, a, r, s_, float(done))\n",
    "        \n",
    "    def sil_store_transition(self, s, a, r, done):\n",
    "        # sil episode caching\n",
    "        for n in range(N_ENVS):\n",
    "            self.running_episodes[n].append([s[n], a[n], r[n]])\n",
    "\n",
    "        for n, d in enumerate(done):\n",
    "            if d:\n",
    "                self.update_buffer(self.running_episodes[n])\n",
    "                self.running_episodes[n] = []\n",
    "                \n",
    "    # SIL update buffer\n",
    "    def update_buffer(self, trajectory):\n",
    "        positive_reward = False\n",
    "        for (ob, a, r) in trajectory:\n",
    "            if r > 0:\n",
    "                positive_reward = True\n",
    "                break\n",
    "        if positive_reward:\n",
    "            self.add_episode(trajectory)\n",
    "                \n",
    "    def add_episode(self, trajectory):\n",
    "        obs = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        dones = []\n",
    "        \n",
    "        for (ob, action, reward) in trajectory:\n",
    "            obs.append(ob)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            dones.append(False)\n",
    "        dones[len(dones)-1]=True\n",
    "        returns = self.discount_with_dones(rewards, dones, GAMMA)\n",
    "        for (ob, action, R) in list(zip(obs, actions, returns)):\n",
    "            self.sil_buffer.add(ob, action, R)\n",
    "            \n",
    "    def discount_with_dones(self, rewards, dones, GAMMA):\n",
    "        discounted = []\n",
    "        r = 0\n",
    "        for reward, done in zip(rewards[::-1], dones[::-1]):\n",
    "            r = reward + GAMMA*r*(1.-done) # fixed off by one bug\n",
    "            discounted.append(r)\n",
    "        return discounted[::-1]\n",
    "\n",
    "    def learn(self):\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # data sample from experience replay\n",
    "        b_state_memory, b_action_memory, b_reward_memory, \\\n",
    "        b_next_state_memory, b_done = self.replay_buffer.sample(BATCH_SIZE)\n",
    "        b_weights, b_idxes = np.ones_like(b_reward_memory), None\n",
    "\n",
    "        b_s = torch.FloatTensor(b_state_memory)\n",
    "        b_a = torch.LongTensor(b_action_memory)\n",
    "        b_r = torch.FloatTensor(b_reward_memory)\n",
    "        b_s_ = torch.FloatTensor(b_next_state_memory)\n",
    "        b_d = torch.FloatTensor(b_done)\n",
    "\n",
    "        if USE_GPU:\n",
    "            b_s, b_a, b_r, b_s_, b_d = b_s.cuda(), b_a.cuda(), b_r.cuda(), b_s_.cuda(), b_d.cuda()\n",
    "\n",
    "        # forward calc\n",
    "        action_log_prob = self.actor_net(b_s)\n",
    "        action_prob = F.softmax(action_log_prob, dim=1)\n",
    "        action_log_prob = F.log_softmax(action_log_prob, dim=1)\n",
    "        cur_value = self.critic_net(b_s).squeeze(1)\n",
    "        next_value = self.critic_target(b_s_)\n",
    "        action_value = self.action_critic_net(b_s)\n",
    "\n",
    "        # critic loss. eq (5) in SAC paper\n",
    "        value_target = (action_value - ENT_COEF * action_log_prob).gather(1, b_a.unsqueeze(1)).squeeze(1)\n",
    "        critic_loss = 0.5 * F.smooth_l1_loss(cur_value, value_target.detach())\n",
    "\n",
    "        # action critic loss. eq (7), (8) in SAC paper\n",
    "        action_value_target = b_r + GAMMA * (1-b_d) * next_value.squeeze(1)\n",
    "        action_critic_loss = 0.5 * F.smooth_l1_loss(action_value.gather(1, \n",
    "            b_a.unsqueeze(1)).squeeze(1), action_value_target.detach())\n",
    "\n",
    "        # actor loss. eq (10) in SAC paper\n",
    "        actor_loss = torch.mean(action_prob*(action_log_prob \\\n",
    "            - F.log_softmax(action_value.detach()/ENT_COEF, dim=1)))\n",
    "\n",
    "        self.actor_opt.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.actor_net.parameters(), MAX_GRAD_NORM)\n",
    "        self.actor_opt.step()\n",
    "\n",
    "        self.critic_opt.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.critic_net.parameters(), MAX_GRAD_NORM)\n",
    "        self.critic_opt.step()\n",
    "\n",
    "        self.action_critic_opt.zero_grad()\n",
    "        action_critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.action_critic_net.parameters(), MAX_GRAD_NORM)\n",
    "        self.action_critic_opt.step()\n",
    "\n",
    "        self.update_target(self.critic_target, self.critic_net, 1e-3)\n",
    "\n",
    "        # SIL update\n",
    "        experience = self.sil_buffer.sample(BATCH_SIZE, beta=0.1)\n",
    "        (sil_b_s, sil_b_a, sil_b_r, sil_b_weights, sil_b_idxes) = experience\n",
    "\n",
    "        sil_b_s = torch.FloatTensor(sil_b_s)\n",
    "        sil_b_a = torch.LongTensor(sil_b_a)\n",
    "        sil_b_r = torch.FloatTensor(sil_b_r)\n",
    "        sil_b_w = torch.Tensor(sil_b_weights)\n",
    "\n",
    "        if USE_GPU:\n",
    "            sil_b_s, sil_b_a, sil_b_r, sil_b_w = sil_b_s.cuda(), sil_b_a.cuda(), sil_b_r.cuda(), sil_b_w.cuda()\n",
    "\n",
    "        # forward calc\n",
    "        sil_action_log_prob = self.actor_net(sil_b_s)\n",
    "        sil_action_log_prob = F.log_softmax(sil_action_log_prob, dim=1)\n",
    "        sil_cur_value = self.critic_net(sil_b_s).squeeze(1)\n",
    "        sil_action_value = self.action_critic_net(sil_b_s)\n",
    "        sil_adv = (torch.clamp(F.relu(sil_b_r - sil_cur_value), 0.0, 1.0)).data.cpu().numpy()\n",
    "\n",
    "        # actor loss. eq (2) in SIL paper\n",
    "        sil_actor_loss = torch.mean( sil_b_w * (-sil_action_log_prob.gather(1,\n",
    "        sil_b_a.unsqueeze(1)).squeeze(1) * torch.clamp(F.relu(sil_b_r - sil_cur_value.detach()),0.0,1.0)))\n",
    "\n",
    "        # critic loss. eq (3) in SIL paper\n",
    "        sil_critic_loss = F.relu(sil_b_r - sil_cur_value)\n",
    "        sil_critic_loss = 0.5 * torch.mean(sil_b_w * (F.smooth_l1_loss(sil_critic_loss,\n",
    "        torch.zeros_like(sil_critic_loss), reduction='none')))\n",
    "        \n",
    "        # action critic_loss. this is not implemented in SIL paper\n",
    "        sil_action_critic_loss = F.relu(sil_b_r \\\n",
    "                            - sil_action_value.gather(1, sil_b_a.unsqueeze(1)).squeeze(1))\n",
    "        sil_action_critic_loss =0.5 * torch.mean(sil_b_w * \\\n",
    "                (F.smooth_l1_loss(sil_action_critic_loss, torch.zeros_like(sil_action_critic_loss)\\\n",
    "                , reduction='none')))\n",
    "\n",
    "        self.actor_opt.zero_grad()\n",
    "        sil_actor_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.actor_net.parameters(), MAX_GRAD_NORM)\n",
    "        self.actor_opt.step()\n",
    "\n",
    "        self.critic_opt.zero_grad()\n",
    "        sil_critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.critic_net.parameters(), MAX_GRAD_NORM)\n",
    "        self.critic_opt.step()\n",
    "        \n",
    "        self.action_critic_opt.zero_grad()\n",
    "        sil_action_critic_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.action_critic_net.parameters(), MAX_GRAD_NORM)\n",
    "        self.action_critic_opt.step()\n",
    "\n",
    "        self.sil_buffer.update_priorities(sil_b_idxes, sil_adv)\n",
    "\n",
    "        return round(float(actor_loss), 4), round(float(critic_loss), 4), round(float(action_critic_loss), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize results!\n",
      "Collecting experience...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a661a4b5dd45daba04e9ca8f376381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=625000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Step: 16000 | Mean ep 100 return:  1.05 | Used Time: 8.16\n",
      "Used Step: 32000 | Mean ep 100 return:  1.32 | Used Time: 75.4\n",
      "Used Step: 48000 | Mean ep 100 return:  0.83 | Used Time: 143.16\n",
      "Used Step: 64000 | Mean ep 100 return:  1.72 | Used Time: 210.72\n",
      "Used Step: 80000 | Mean ep 100 return:  1.74 | Used Time: 278.02\n",
      "Used Step: 96000 | Mean ep 100 return:  2.04 | Used Time: 345.26\n",
      "Used Step: 112000 | Mean ep 100 return:  3.59 | Used Time: 412.44\n",
      "Used Step: 128000 | Mean ep 100 return:  5.6 | Used Time: 479.33\n",
      "Used Step: 144000 | Mean ep 100 return:  7.44 | Used Time: 546.2\n",
      "Used Step: 160000 | Mean ep 100 return:  8.66 | Used Time: 613.11\n",
      "Used Step: 176000 | Mean ep 100 return:  9.61 | Used Time: 680.01\n",
      "Used Step: 192000 | Mean ep 100 return:  10.64 | Used Time: 746.94\n",
      "Used Step: 208000 | Mean ep 100 return:  11.6 | Used Time: 813.85\n",
      "Used Step: 224000 | Mean ep 100 return:  13.17 | Used Time: 880.74\n",
      "Used Step: 240000 | Mean ep 100 return:  14.12 | Used Time: 947.66\n",
      "Used Step: 256000 | Mean ep 100 return:  15.09 | Used Time: 1014.56\n",
      "Used Step: 272000 | Mean ep 100 return:  16.46 | Used Time: 1081.47\n",
      "Used Step: 288000 | Mean ep 100 return:  17.19 | Used Time: 1148.44\n",
      "Used Step: 304000 | Mean ep 100 return:  17.68 | Used Time: 1215.52\n",
      "Used Step: 320000 | Mean ep 100 return:  17.81 | Used Time: 1282.58\n",
      "Used Step: 336000 | Mean ep 100 return:  18.1 | Used Time: 1349.59\n",
      "Used Step: 352000 | Mean ep 100 return:  18.68 | Used Time: 1416.56\n",
      "Used Step: 368000 | Mean ep 100 return:  19.5 | Used Time: 1483.65\n",
      "Used Step: 384000 | Mean ep 100 return:  19.83 | Used Time: 1550.75\n",
      "Used Step: 400000 | Mean ep 100 return:  20.21 | Used Time: 1617.79\n",
      "Used Step: 416000 | Mean ep 100 return:  20.48 | Used Time: 1684.96\n",
      "Used Step: 432000 | Mean ep 100 return:  21.21 | Used Time: 1752.01\n",
      "Used Step: 448000 | Mean ep 100 return:  21.9 | Used Time: 1819.23\n",
      "Used Step: 464000 | Mean ep 100 return:  21.41 | Used Time: 1886.39\n",
      "Used Step: 480000 | Mean ep 100 return:  21.73 | Used Time: 1953.58\n",
      "Used Step: 496000 | Mean ep 100 return:  22.77 | Used Time: 2020.73\n",
      "Used Step: 512000 | Mean ep 100 return:  22.38 | Used Time: 2088.06\n",
      "Used Step: 528000 | Mean ep 100 return:  22.79 | Used Time: 2155.16\n",
      "Used Step: 544000 | Mean ep 100 return:  24.67 | Used Time: 2222.31\n",
      "Used Step: 560000 | Mean ep 100 return:  26.09 | Used Time: 2289.47\n",
      "Used Step: 576000 | Mean ep 100 return:  27.22 | Used Time: 2356.56\n",
      "Used Step: 592000 | Mean ep 100 return:  29.41 | Used Time: 2423.61\n",
      "Used Step: 608000 | Mean ep 100 return:  30.75 | Used Time: 2490.73\n",
      "Used Step: 624000 | Mean ep 100 return:  31.52 | Used Time: 2557.91\n",
      "Used Step: 640000 | Mean ep 100 return:  30.6 | Used Time: 2625.05\n",
      "Used Step: 656000 | Mean ep 100 return:  30.98 | Used Time: 2692.08\n",
      "Used Step: 672000 | Mean ep 100 return:  31.85 | Used Time: 2759.3\n",
      "Used Step: 688000 | Mean ep 100 return:  31.45 | Used Time: 2826.42\n",
      "Used Step: 704000 | Mean ep 100 return:  32.14 | Used Time: 2893.53\n",
      "Used Step: 720000 | Mean ep 100 return:  33.32 | Used Time: 2960.66\n",
      "Used Step: 736000 | Mean ep 100 return:  34.31 | Used Time: 3027.81\n",
      "Used Step: 752000 | Mean ep 100 return:  34.8 | Used Time: 3094.87\n",
      "Used Step: 768000 | Mean ep 100 return:  34.33 | Used Time: 3162.01\n",
      "Used Step: 784000 | Mean ep 100 return:  35.0 | Used Time: 3229.15\n",
      "Used Step: 800000 | Mean ep 100 return:  36.19 | Used Time: 3296.23\n",
      "Used Step: 816000 | Mean ep 100 return:  35.91 | Used Time: 3363.27\n",
      "Used Step: 832000 | Mean ep 100 return:  37.45 | Used Time: 3430.32\n",
      "Used Step: 848000 | Mean ep 100 return:  39.59 | Used Time: 3497.38\n",
      "Used Step: 864000 | Mean ep 100 return:  41.14 | Used Time: 3564.46\n",
      "Used Step: 880000 | Mean ep 100 return:  41.85 | Used Time: 3631.6\n",
      "Used Step: 896000 | Mean ep 100 return:  43.63 | Used Time: 3698.59\n",
      "Used Step: 912000 | Mean ep 100 return:  44.88 | Used Time: 3765.69\n",
      "Used Step: 928000 | Mean ep 100 return:  44.99 | Used Time: 3832.62\n",
      "Used Step: 944000 | Mean ep 100 return:  46.31 | Used Time: 3899.61\n",
      "Used Step: 960000 | Mean ep 100 return:  45.96 | Used Time: 3966.65\n",
      "Used Step: 976000 | Mean ep 100 return:  47.26 | Used Time: 4033.75\n",
      "Used Step: 992000 | Mean ep 100 return:  47.71 | Used Time: 4100.68\n",
      "Used Step: 1008000 | Mean ep 100 return:  49.28 | Used Time: 4167.87\n",
      "Used Step: 1024000 | Mean ep 100 return:  48.8 | Used Time: 4234.85\n",
      "Used Step: 1040000 | Mean ep 100 return:  50.62 | Used Time: 4301.82\n",
      "Used Step: 1056000 | Mean ep 100 return:  49.85 | Used Time: 4368.8\n",
      "Used Step: 1072000 | Mean ep 100 return:  49.82 | Used Time: 4435.72\n",
      "Used Step: 1088000 | Mean ep 100 return:  51.08 | Used Time: 4502.73\n",
      "Used Step: 1104000 | Mean ep 100 return:  50.73 | Used Time: 4569.57\n",
      "Used Step: 1120000 | Mean ep 100 return:  51.85 | Used Time: 4636.6\n",
      "Used Step: 1136000 | Mean ep 100 return:  52.98 | Used Time: 4703.61\n",
      "Used Step: 1152000 | Mean ep 100 return:  53.72 | Used Time: 4770.49\n",
      "Used Step: 1168000 | Mean ep 100 return:  55.36 | Used Time: 4837.5\n",
      "Used Step: 1184000 | Mean ep 100 return:  57.53 | Used Time: 4904.44\n",
      "Used Step: 1200000 | Mean ep 100 return:  59.29 | Used Time: 4971.42\n",
      "Used Step: 1216000 | Mean ep 100 return:  59.04 | Used Time: 5038.38\n",
      "Used Step: 1232000 | Mean ep 100 return:  60.96 | Used Time: 5105.35\n",
      "Used Step: 1248000 | Mean ep 100 return:  62.96 | Used Time: 5172.24\n",
      "Used Step: 1264000 | Mean ep 100 return:  63.19 | Used Time: 5239.13\n",
      "Used Step: 1280000 | Mean ep 100 return:  64.07 | Used Time: 5306.14\n",
      "Used Step: 1296000 | Mean ep 100 return:  63.02 | Used Time: 5373.11\n",
      "Used Step: 1312000 | Mean ep 100 return:  64.73 | Used Time: 5440.02\n",
      "Used Step: 1328000 | Mean ep 100 return:  63.7 | Used Time: 5507.03\n",
      "Used Step: 1344000 | Mean ep 100 return:  63.28 | Used Time: 5573.96\n",
      "Used Step: 1360000 | Mean ep 100 return:  63.72 | Used Time: 5640.94\n",
      "Used Step: 1376000 | Mean ep 100 return:  64.98 | Used Time: 5707.89\n",
      "Used Step: 1392000 | Mean ep 100 return:  64.33 | Used Time: 5774.81\n",
      "Used Step: 1408000 | Mean ep 100 return:  67.45 | Used Time: 5841.75\n",
      "Used Step: 1424000 | Mean ep 100 return:  67.64 | Used Time: 5908.71\n",
      "Used Step: 1440000 | Mean ep 100 return:  68.46 | Used Time: 5975.57\n",
      "Used Step: 1456000 | Mean ep 100 return:  69.48 | Used Time: 6042.54\n",
      "Used Step: 1472000 | Mean ep 100 return:  70.53 | Used Time: 6109.43\n",
      "Used Step: 1488000 | Mean ep 100 return:  71.9 | Used Time: 6176.41\n",
      "Used Step: 1504000 | Mean ep 100 return:  73.71 | Used Time: 6243.4\n",
      "Used Step: 1520000 | Mean ep 100 return:  72.97 | Used Time: 6310.31\n",
      "Used Step: 1536000 | Mean ep 100 return:  58.74 | Used Time: 6377.58\n",
      "Used Step: 1552000 | Mean ep 100 return:  37.57 | Used Time: 6444.67\n",
      "Used Step: 1568000 | Mean ep 100 return:  11.78 | Used Time: 6511.87\n",
      "Used Step: 1584000 | Mean ep 100 return:  10.65 | Used Time: 6578.71\n",
      "Used Step: 1600000 | Mean ep 100 return:  17.37 | Used Time: 6645.7\n",
      "Used Step: 1616000 | Mean ep 100 return:  24.75 | Used Time: 6712.67\n",
      "Used Step: 1632000 | Mean ep 100 return:  33.72 | Used Time: 6779.68\n",
      "Used Step: 1648000 | Mean ep 100 return:  39.0 | Used Time: 6846.57\n",
      "Used Step: 1664000 | Mean ep 100 return:  47.23 | Used Time: 6913.44\n",
      "Used Step: 1680000 | Mean ep 100 return:  59.49 | Used Time: 6980.65\n",
      "Used Step: 1696000 | Mean ep 100 return:  43.97 | Used Time: 7047.76\n",
      "Used Step: 1712000 | Mean ep 100 return:  34.29 | Used Time: 7114.55\n",
      "Used Step: 1728000 | Mean ep 100 return:  33.63 | Used Time: 7181.52\n",
      "Used Step: 1744000 | Mean ep 100 return:  35.17 | Used Time: 7248.58\n",
      "Used Step: 1760000 | Mean ep 100 return:  35.06 | Used Time: 7315.47\n",
      "Used Step: 1776000 | Mean ep 100 return:  45.78 | Used Time: 7382.42\n",
      "Used Step: 1792000 | Mean ep 100 return:  56.87 | Used Time: 7449.41\n",
      "Used Step: 1808000 | Mean ep 100 return:  64.06 | Used Time: 7516.2\n",
      "Used Step: 1824000 | Mean ep 100 return:  75.28 | Used Time: 7583.16\n",
      "Used Step: 1840000 | Mean ep 100 return:  83.83 | Used Time: 7650.08\n",
      "Used Step: 1856000 | Mean ep 100 return:  92.22 | Used Time: 7716.98\n",
      "Used Step: 1872000 | Mean ep 100 return:  94.15 | Used Time: 7783.93\n",
      "Used Step: 1888000 | Mean ep 100 return:  96.79 | Used Time: 7850.94\n",
      "Used Step: 1904000 | Mean ep 100 return:  97.57 | Used Time: 7917.82\n",
      "Used Step: 1920000 | Mean ep 100 return:  97.37 | Used Time: 7984.64\n",
      "Used Step: 1936000 | Mean ep 100 return:  98.32 | Used Time: 8051.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Step: 1952000 | Mean ep 100 return:  99.09 | Used Time: 8118.41\n",
      "Used Step: 1968000 | Mean ep 100 return:  107.62 | Used Time: 8185.29\n",
      "Used Step: 1984000 | Mean ep 100 return:  109.21 | Used Time: 8252.23\n",
      "Used Step: 2000000 | Mean ep 100 return:  115.56 | Used Time: 8319.23\n",
      "Used Step: 2016000 | Mean ep 100 return:  118.0 | Used Time: 8386.18\n",
      "Used Step: 2032000 | Mean ep 100 return:  122.9 | Used Time: 8453.03\n",
      "Used Step: 2048000 | Mean ep 100 return:  125.56 | Used Time: 8519.94\n",
      "Used Step: 2064000 | Mean ep 100 return:  131.9 | Used Time: 8586.92\n",
      "Used Step: 2080000 | Mean ep 100 return:  134.55 | Used Time: 8653.91\n",
      "Used Step: 2096000 | Mean ep 100 return:  137.57 | Used Time: 8720.81\n",
      "Used Step: 2112000 | Mean ep 100 return:  134.21 | Used Time: 8787.75\n",
      "Used Step: 2128000 | Mean ep 100 return:  140.23 | Used Time: 8854.67\n",
      "Used Step: 2144000 | Mean ep 100 return:  141.03 | Used Time: 8921.63\n",
      "Used Step: 2160000 | Mean ep 100 return:  136.35 | Used Time: 8988.65\n",
      "Used Step: 2176000 | Mean ep 100 return:  130.48 | Used Time: 9055.6\n",
      "Used Step: 2192000 | Mean ep 100 return:  133.71 | Used Time: 9122.71\n",
      "Used Step: 2208000 | Mean ep 100 return:  133.13 | Used Time: 9189.69\n",
      "Used Step: 2224000 | Mean ep 100 return:  127.4 | Used Time: 9256.69\n",
      "Used Step: 2240000 | Mean ep 100 return:  128.65 | Used Time: 9323.61\n",
      "Used Step: 2256000 | Mean ep 100 return:  131.81 | Used Time: 9390.57\n",
      "Used Step: 2272000 | Mean ep 100 return:  128.04 | Used Time: 9457.5\n",
      "Used Step: 2288000 | Mean ep 100 return:  124.01 | Used Time: 9524.39\n",
      "Used Step: 2304000 | Mean ep 100 return:  125.63 | Used Time: 9591.44\n",
      "Used Step: 2320000 | Mean ep 100 return:  127.35 | Used Time: 9658.41\n",
      "Used Step: 2336000 | Mean ep 100 return:  128.25 | Used Time: 9725.25\n",
      "Used Step: 2352000 | Mean ep 100 return:  131.42 | Used Time: 9792.25\n",
      "Used Step: 2368000 | Mean ep 100 return:  138.11 | Used Time: 9859.16\n",
      "Used Step: 2384000 | Mean ep 100 return:  147.72 | Used Time: 9926.14\n",
      "Used Step: 2400000 | Mean ep 100 return:  144.11 | Used Time: 9993.02\n",
      "Used Step: 2416000 | Mean ep 100 return:  145.91 | Used Time: 10059.88\n",
      "Used Step: 2432000 | Mean ep 100 return:  153.17 | Used Time: 10126.7\n",
      "Used Step: 2448000 | Mean ep 100 return:  157.86 | Used Time: 10193.77\n",
      "Used Step: 2464000 | Mean ep 100 return:  161.61 | Used Time: 10260.67\n",
      "Used Step: 2480000 | Mean ep 100 return:  172.8 | Used Time: 10327.67\n",
      "Used Step: 2496000 | Mean ep 100 return:  177.36 | Used Time: 10394.6\n",
      "Used Step: 2512000 | Mean ep 100 return:  180.38 | Used Time: 10461.48\n",
      "Used Step: 2528000 | Mean ep 100 return:  180.16 | Used Time: 10528.34\n",
      "Used Step: 2544000 | Mean ep 100 return:  182.56 | Used Time: 10595.15\n",
      "Used Step: 2560000 | Mean ep 100 return:  188.24 | Used Time: 10662.19\n",
      "Used Step: 2576000 | Mean ep 100 return:  188.74 | Used Time: 10729.02\n",
      "Used Step: 2592000 | Mean ep 100 return:  187.52 | Used Time: 10795.99\n",
      "Used Step: 2608000 | Mean ep 100 return:  188.35 | Used Time: 10862.88\n",
      "Used Step: 2624000 | Mean ep 100 return:  193.35 | Used Time: 10929.92\n",
      "Used Step: 2640000 | Mean ep 100 return:  190.59 | Used Time: 10996.79\n",
      "Used Step: 2656000 | Mean ep 100 return:  192.32 | Used Time: 11063.79\n",
      "Used Step: 2672000 | Mean ep 100 return:  193.19 | Used Time: 11130.51\n",
      "Used Step: 2688000 | Mean ep 100 return:  197.11 | Used Time: 11197.31\n",
      "Used Step: 2704000 | Mean ep 100 return:  200.05 | Used Time: 11264.19\n",
      "Used Step: 2720000 | Mean ep 100 return:  205.39 | Used Time: 11331.18\n",
      "Used Step: 2736000 | Mean ep 100 return:  210.76 | Used Time: 11398.18\n",
      "Used Step: 2752000 | Mean ep 100 return:  209.94 | Used Time: 11464.86\n",
      "Used Step: 2768000 | Mean ep 100 return:  210.46 | Used Time: 11531.8\n",
      "Used Step: 2784000 | Mean ep 100 return:  212.85 | Used Time: 11598.68\n",
      "Used Step: 2800000 | Mean ep 100 return:  217.84 | Used Time: 11665.69\n",
      "Used Step: 2816000 | Mean ep 100 return:  219.96 | Used Time: 11732.77\n",
      "Used Step: 2832000 | Mean ep 100 return:  225.97 | Used Time: 11799.73\n",
      "Used Step: 2848000 | Mean ep 100 return:  229.33 | Used Time: 11866.71\n",
      "Used Step: 2864000 | Mean ep 100 return:  227.78 | Used Time: 11933.8\n",
      "Used Step: 2880000 | Mean ep 100 return:  229.41 | Used Time: 12000.78\n",
      "Used Step: 2896000 | Mean ep 100 return:  226.75 | Used Time: 12067.73\n",
      "Used Step: 2912000 | Mean ep 100 return:  229.16 | Used Time: 12134.76\n",
      "Used Step: 2928000 | Mean ep 100 return:  239.94 | Used Time: 12201.67\n",
      "Used Step: 2944000 | Mean ep 100 return:  242.46 | Used Time: 12268.45\n",
      "Used Step: 2960000 | Mean ep 100 return:  247.3 | Used Time: 12335.45\n",
      "Used Step: 2976000 | Mean ep 100 return:  251.13 | Used Time: 12402.28\n",
      "Used Step: 2992000 | Mean ep 100 return:  249.15 | Used Time: 12469.43\n",
      "Used Step: 3008000 | Mean ep 100 return:  247.93 | Used Time: 12536.31\n",
      "Used Step: 3024000 | Mean ep 100 return:  247.98 | Used Time: 12603.24\n",
      "Used Step: 3040000 | Mean ep 100 return:  253.2 | Used Time: 12670.06\n",
      "Used Step: 3056000 | Mean ep 100 return:  263.1 | Used Time: 12737.09\n",
      "Used Step: 3072000 | Mean ep 100 return:  268.75 | Used Time: 12803.91\n",
      "Used Step: 3088000 | Mean ep 100 return:  274.65 | Used Time: 12870.81\n",
      "Used Step: 3104000 | Mean ep 100 return:  280.18 | Used Time: 12937.58\n",
      "Used Step: 3120000 | Mean ep 100 return:  281.76 | Used Time: 13004.45\n",
      "Used Step: 3136000 | Mean ep 100 return:  285.29 | Used Time: 13071.38\n",
      "Used Step: 3152000 | Mean ep 100 return:  280.78 | Used Time: 13138.4\n",
      "Used Step: 3168000 | Mean ep 100 return:  284.61 | Used Time: 13205.17\n",
      "Used Step: 3184000 | Mean ep 100 return:  288.08 | Used Time: 13271.91\n",
      "Used Step: 3200000 | Mean ep 100 return:  291.06 | Used Time: 13338.83\n",
      "Used Step: 3216000 | Mean ep 100 return:  294.01 | Used Time: 13405.59\n",
      "Used Step: 3232000 | Mean ep 100 return:  295.75 | Used Time: 13472.49\n",
      "Used Step: 3248000 | Mean ep 100 return:  299.4 | Used Time: 13539.2\n",
      "Used Step: 3264000 | Mean ep 100 return:  304.07 | Used Time: 13606.01\n",
      "Used Step: 3280000 | Mean ep 100 return:  311.03 | Used Time: 13672.78\n",
      "Used Step: 3296000 | Mean ep 100 return:  313.02 | Used Time: 13739.55\n",
      "Used Step: 3312000 | Mean ep 100 return:  313.83 | Used Time: 13806.5\n",
      "Used Step: 3328000 | Mean ep 100 return:  316.18 | Used Time: 13873.41\n",
      "Used Step: 3344000 | Mean ep 100 return:  318.45 | Used Time: 13940.31\n",
      "Used Step: 3360000 | Mean ep 100 return:  321.25 | Used Time: 14007.22\n",
      "Used Step: 3376000 | Mean ep 100 return:  323.78 | Used Time: 14074.16\n",
      "Used Step: 3392000 | Mean ep 100 return:  324.27 | Used Time: 14140.92\n",
      "Used Step: 3408000 | Mean ep 100 return:  323.52 | Used Time: 14207.71\n",
      "Used Step: 3424000 | Mean ep 100 return:  323.76 | Used Time: 14274.61\n",
      "Used Step: 3440000 | Mean ep 100 return:  325.18 | Used Time: 14341.4\n",
      "Used Step: 3456000 | Mean ep 100 return:  326.65 | Used Time: 14408.36\n",
      "Used Step: 3472000 | Mean ep 100 return:  325.88 | Used Time: 14475.15\n",
      "Used Step: 3488000 | Mean ep 100 return:  324.4 | Used Time: 14542.07\n",
      "Used Step: 3504000 | Mean ep 100 return:  319.66 | Used Time: 14608.91\n",
      "Used Step: 3520000 | Mean ep 100 return:  322.0 | Used Time: 14675.95\n",
      "Used Step: 3536000 | Mean ep 100 return:  324.93 | Used Time: 14742.74\n",
      "Used Step: 3552000 | Mean ep 100 return:  325.25 | Used Time: 14809.61\n",
      "Used Step: 3568000 | Mean ep 100 return:  322.1 | Used Time: 14876.53\n",
      "Used Step: 3584000 | Mean ep 100 return:  324.06 | Used Time: 14943.35\n",
      "Used Step: 3600000 | Mean ep 100 return:  325.78 | Used Time: 15010.42\n",
      "Used Step: 3616000 | Mean ep 100 return:  322.77 | Used Time: 15077.3\n",
      "Used Step: 3632000 | Mean ep 100 return:  319.05 | Used Time: 15144.25\n",
      "Used Step: 3648000 | Mean ep 100 return:  319.89 | Used Time: 15211.15\n",
      "Used Step: 3664000 | Mean ep 100 return:  318.27 | Used Time: 15277.76\n",
      "Used Step: 3680000 | Mean ep 100 return:  317.49 | Used Time: 15344.6\n",
      "Used Step: 3696000 | Mean ep 100 return:  318.95 | Used Time: 15411.36\n",
      "Used Step: 3712000 | Mean ep 100 return:  321.67 | Used Time: 15478.22\n",
      "Used Step: 3728000 | Mean ep 100 return:  317.09 | Used Time: 15545.14\n",
      "Used Step: 3744000 | Mean ep 100 return:  313.34 | Used Time: 15611.97\n",
      "Used Step: 3760000 | Mean ep 100 return:  311.1 | Used Time: 15678.58\n",
      "Used Step: 3776000 | Mean ep 100 return:  319.55 | Used Time: 15745.41\n",
      "Used Step: 3792000 | Mean ep 100 return:  320.31 | Used Time: 15812.25\n",
      "Used Step: 3808000 | Mean ep 100 return:  322.17 | Used Time: 15878.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Step: 3824000 | Mean ep 100 return:  330.11 | Used Time: 15945.69\n",
      "Used Step: 3840000 | Mean ep 100 return:  331.48 | Used Time: 16012.53\n",
      "Used Step: 3856000 | Mean ep 100 return:  330.89 | Used Time: 16079.24\n",
      "Used Step: 3872000 | Mean ep 100 return:  323.49 | Used Time: 16146.09\n",
      "Used Step: 3888000 | Mean ep 100 return:  323.76 | Used Time: 16212.73\n",
      "Used Step: 3904000 | Mean ep 100 return:  326.31 | Used Time: 16279.61\n",
      "Used Step: 3920000 | Mean ep 100 return:  327.39 | Used Time: 16346.35\n",
      "Used Step: 3936000 | Mean ep 100 return:  333.28 | Used Time: 16413.89\n",
      "Used Step: 3952000 | Mean ep 100 return:  336.59 | Used Time: 16480.67\n",
      "Used Step: 3968000 | Mean ep 100 return:  331.18 | Used Time: 16547.33\n",
      "Used Step: 3984000 | Mean ep 100 return:  320.28 | Used Time: 16614.0\n",
      "Used Step: 4000000 | Mean ep 100 return:  323.17 | Used Time: 16680.61\n",
      "Used Step: 4016000 | Mean ep 100 return:  326.2 | Used Time: 16747.36\n",
      "Used Step: 4032000 | Mean ep 100 return:  321.5 | Used Time: 16813.98\n",
      "Used Step: 4048000 | Mean ep 100 return:  322.04 | Used Time: 16880.57\n",
      "Used Step: 4064000 | Mean ep 100 return:  322.79 | Used Time: 16946.89\n",
      "Used Step: 4080000 | Mean ep 100 return:  327.78 | Used Time: 17013.44\n",
      "Used Step: 4096000 | Mean ep 100 return:  325.43 | Used Time: 17080.08\n",
      "Used Step: 4112000 | Mean ep 100 return:  322.17 | Used Time: 17146.66\n",
      "Used Step: 4128000 | Mean ep 100 return:  325.57 | Used Time: 17213.33\n",
      "Used Step: 4144000 | Mean ep 100 return:  331.07 | Used Time: 17279.78\n",
      "Used Step: 4160000 | Mean ep 100 return:  327.63 | Used Time: 17346.43\n",
      "Used Step: 4176000 | Mean ep 100 return:  328.15 | Used Time: 17412.96\n",
      "Used Step: 4192000 | Mean ep 100 return:  331.73 | Used Time: 17479.51\n",
      "Used Step: 4208000 | Mean ep 100 return:  333.56 | Used Time: 17546.1\n",
      "Used Step: 4224000 | Mean ep 100 return:  333.23 | Used Time: 17612.62\n",
      "Used Step: 4240000 | Mean ep 100 return:  335.09 | Used Time: 17679.17\n",
      "Used Step: 4256000 | Mean ep 100 return:  334.26 | Used Time: 17745.81\n",
      "Used Step: 4272000 | Mean ep 100 return:  337.73 | Used Time: 17812.3\n",
      "Used Step: 4288000 | Mean ep 100 return:  336.25 | Used Time: 17878.95\n",
      "Used Step: 4304000 | Mean ep 100 return:  338.34 | Used Time: 17945.35\n",
      "Used Step: 4320000 | Mean ep 100 return:  337.29 | Used Time: 18011.84\n",
      "Used Step: 4336000 | Mean ep 100 return:  337.59 | Used Time: 18078.66\n",
      "Used Step: 4352000 | Mean ep 100 return:  334.26 | Used Time: 18145.76\n",
      "Used Step: 4368000 | Mean ep 100 return:  330.8 | Used Time: 18212.79\n",
      "Used Step: 4384000 | Mean ep 100 return:  333.81 | Used Time: 18279.39\n",
      "Used Step: 4400000 | Mean ep 100 return:  330.32 | Used Time: 18345.93\n",
      "Used Step: 4416000 | Mean ep 100 return:  329.41 | Used Time: 18412.55\n",
      "Used Step: 4432000 | Mean ep 100 return:  333.25 | Used Time: 18479.24\n",
      "Used Step: 4448000 | Mean ep 100 return:  337.18 | Used Time: 18546.03\n",
      "Used Step: 4464000 | Mean ep 100 return:  337.53 | Used Time: 18612.53\n",
      "Used Step: 4480000 | Mean ep 100 return:  339.54 | Used Time: 18679.28\n",
      "Used Step: 4496000 | Mean ep 100 return:  343.93 | Used Time: 18746.86\n",
      "Used Step: 4512000 | Mean ep 100 return:  343.7 | Used Time: 18814.31\n",
      "Used Step: 4528000 | Mean ep 100 return:  334.17 | Used Time: 18881.75\n",
      "Used Step: 4544000 | Mean ep 100 return:  336.33 | Used Time: 18948.92\n",
      "Used Step: 4560000 | Mean ep 100 return:  338.82 | Used Time: 19016.15\n",
      "Used Step: 4576000 | Mean ep 100 return:  338.47 | Used Time: 19083.24\n",
      "Used Step: 4592000 | Mean ep 100 return:  339.22 | Used Time: 19150.29\n",
      "Used Step: 4608000 | Mean ep 100 return:  344.74 | Used Time: 19217.38\n",
      "Used Step: 4624000 | Mean ep 100 return:  348.54 | Used Time: 19284.79\n",
      "Used Step: 4640000 | Mean ep 100 return:  348.07 | Used Time: 19352.23\n",
      "Used Step: 4656000 | Mean ep 100 return:  343.76 | Used Time: 19419.39\n",
      "Used Step: 4672000 | Mean ep 100 return:  339.59 | Used Time: 19486.94\n",
      "Used Step: 4688000 | Mean ep 100 return:  338.6 | Used Time: 19554.68\n",
      "Used Step: 4704000 | Mean ep 100 return:  338.79 | Used Time: 19622.53\n",
      "Used Step: 4720000 | Mean ep 100 return:  340.09 | Used Time: 19689.98\n",
      "Used Step: 4736000 | Mean ep 100 return:  348.01 | Used Time: 19757.25\n",
      "Used Step: 4752000 | Mean ep 100 return:  345.13 | Used Time: 19824.47\n",
      "Used Step: 4768000 | Mean ep 100 return:  338.37 | Used Time: 19891.52\n",
      "Used Step: 4784000 | Mean ep 100 return:  331.27 | Used Time: 19958.52\n",
      "Used Step: 4800000 | Mean ep 100 return:  333.71 | Used Time: 20025.47\n",
      "Used Step: 4816000 | Mean ep 100 return:  327.76 | Used Time: 20092.89\n",
      "Used Step: 4832000 | Mean ep 100 return:  325.82 | Used Time: 20160.23\n",
      "Used Step: 4848000 | Mean ep 100 return:  321.92 | Used Time: 20227.95\n",
      "Used Step: 4864000 | Mean ep 100 return:  321.96 | Used Time: 20296.04\n",
      "Used Step: 4880000 | Mean ep 100 return:  325.25 | Used Time: 20363.61\n",
      "Used Step: 4896000 | Mean ep 100 return:  326.95 | Used Time: 20430.87\n",
      "Used Step: 4912000 | Mean ep 100 return:  330.07 | Used Time: 20498.26\n",
      "Used Step: 4928000 | Mean ep 100 return:  327.71 | Used Time: 20565.57\n",
      "Used Step: 4944000 | Mean ep 100 return:  329.5 | Used Time: 20632.58\n",
      "Used Step: 4960000 | Mean ep 100 return:  332.74 | Used Time: 20700.22\n",
      "Used Step: 4976000 | Mean ep 100 return:  340.25 | Used Time: 20767.5\n",
      "Used Step: 4992000 | Mean ep 100 return:  341.06 | Used Time: 20834.38\n",
      "Used Step: 5008000 | Mean ep 100 return:  346.12 | Used Time: 20901.83\n",
      "Used Step: 5024000 | Mean ep 100 return:  348.53 | Used Time: 20968.82\n",
      "Used Step: 5040000 | Mean ep 100 return:  350.01 | Used Time: 21036.37\n",
      "Used Step: 5056000 | Mean ep 100 return:  356.01 | Used Time: 21103.84\n",
      "Used Step: 5072000 | Mean ep 100 return:  353.6 | Used Time: 21171.48\n",
      "Used Step: 5088000 | Mean ep 100 return:  353.48 | Used Time: 21239.21\n",
      "Used Step: 5104000 | Mean ep 100 return:  350.78 | Used Time: 21306.94\n",
      "Used Step: 5120000 | Mean ep 100 return:  348.86 | Used Time: 21374.33\n",
      "Used Step: 5136000 | Mean ep 100 return:  341.1 | Used Time: 21441.84\n",
      "Used Step: 5152000 | Mean ep 100 return:  333.34 | Used Time: 21509.1\n",
      "Used Step: 5168000 | Mean ep 100 return:  328.49 | Used Time: 21576.28\n",
      "Used Step: 5184000 | Mean ep 100 return:  313.81 | Used Time: 21643.7\n",
      "Used Step: 5200000 | Mean ep 100 return:  303.26 | Used Time: 21710.89\n",
      "Used Step: 5216000 | Mean ep 100 return:  305.55 | Used Time: 21778.04\n",
      "Used Step: 5232000 | Mean ep 100 return:  302.45 | Used Time: 21845.21\n",
      "Used Step: 5248000 | Mean ep 100 return:  295.7 | Used Time: 21912.78\n",
      "Used Step: 5264000 | Mean ep 100 return:  294.32 | Used Time: 21980.04\n",
      "Used Step: 5280000 | Mean ep 100 return:  304.84 | Used Time: 22047.35\n",
      "Used Step: 5296000 | Mean ep 100 return:  304.12 | Used Time: 22114.58\n",
      "Used Step: 5312000 | Mean ep 100 return:  308.28 | Used Time: 22181.93\n",
      "Used Step: 5328000 | Mean ep 100 return:  312.93 | Used Time: 22249.33\n",
      "Used Step: 5344000 | Mean ep 100 return:  314.9 | Used Time: 22316.68\n",
      "Used Step: 5360000 | Mean ep 100 return:  325.17 | Used Time: 22384.04\n",
      "Used Step: 5376000 | Mean ep 100 return:  323.31 | Used Time: 22451.43\n",
      "Used Step: 5392000 | Mean ep 100 return:  333.28 | Used Time: 22518.78\n",
      "Used Step: 5408000 | Mean ep 100 return:  333.76 | Used Time: 22586.09\n",
      "Used Step: 5424000 | Mean ep 100 return:  344.76 | Used Time: 22653.26\n",
      "Used Step: 5440000 | Mean ep 100 return:  343.01 | Used Time: 22720.42\n",
      "Used Step: 5456000 | Mean ep 100 return:  342.24 | Used Time: 22787.77\n",
      "Used Step: 5472000 | Mean ep 100 return:  346.3 | Used Time: 22855.23\n",
      "Used Step: 5488000 | Mean ep 100 return:  348.21 | Used Time: 22922.27\n",
      "Used Step: 5504000 | Mean ep 100 return:  347.28 | Used Time: 22989.4\n",
      "Used Step: 5520000 | Mean ep 100 return:  340.99 | Used Time: 23056.79\n",
      "Used Step: 5536000 | Mean ep 100 return:  341.79 | Used Time: 23123.98\n",
      "Used Step: 5552000 | Mean ep 100 return:  340.4 | Used Time: 23191.28\n",
      "Used Step: 5568000 | Mean ep 100 return:  338.3 | Used Time: 23258.48\n",
      "Used Step: 5584000 | Mean ep 100 return:  334.47 | Used Time: 23325.56\n",
      "Used Step: 5600000 | Mean ep 100 return:  331.95 | Used Time: 23392.99\n",
      "Used Step: 5616000 | Mean ep 100 return:  336.72 | Used Time: 23459.97\n",
      "Used Step: 5632000 | Mean ep 100 return:  337.0 | Used Time: 23527.23\n",
      "Used Step: 5648000 | Mean ep 100 return:  337.38 | Used Time: 23594.59\n",
      "Used Step: 5664000 | Mean ep 100 return:  343.74 | Used Time: 23661.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Step: 5680000 | Mean ep 100 return:  345.81 | Used Time: 23728.87\n",
      "Used Step: 5696000 | Mean ep 100 return:  349.57 | Used Time: 23796.04\n",
      "Used Step: 5712000 | Mean ep 100 return:  342.78 | Used Time: 23862.94\n",
      "Used Step: 5728000 | Mean ep 100 return:  352.44 | Used Time: 23930.03\n",
      "Used Step: 5744000 | Mean ep 100 return:  352.02 | Used Time: 23996.94\n",
      "Used Step: 5760000 | Mean ep 100 return:  358.2 | Used Time: 24063.82\n",
      "Used Step: 5776000 | Mean ep 100 return:  360.09 | Used Time: 24130.79\n",
      "Used Step: 5792000 | Mean ep 100 return:  362.83 | Used Time: 24197.77\n",
      "Used Step: 5808000 | Mean ep 100 return:  368.18 | Used Time: 24264.72\n",
      "Used Step: 5824000 | Mean ep 100 return:  364.36 | Used Time: 24331.36\n",
      "Used Step: 5840000 | Mean ep 100 return:  365.9 | Used Time: 24398.38\n",
      "Used Step: 5856000 | Mean ep 100 return:  366.82 | Used Time: 24465.28\n",
      "Used Step: 5872000 | Mean ep 100 return:  357.78 | Used Time: 24532.28\n",
      "Used Step: 5888000 | Mean ep 100 return:  348.34 | Used Time: 24599.27\n",
      "Used Step: 5904000 | Mean ep 100 return:  348.24 | Used Time: 24666.17\n",
      "Used Step: 5920000 | Mean ep 100 return:  342.0 | Used Time: 24733.12\n",
      "Used Step: 5936000 | Mean ep 100 return:  334.38 | Used Time: 24800.11\n",
      "Used Step: 5952000 | Mean ep 100 return:  326.3 | Used Time: 24866.85\n",
      "Used Step: 5968000 | Mean ep 100 return:  324.51 | Used Time: 24933.72\n",
      "Used Step: 5984000 | Mean ep 100 return:  320.0 | Used Time: 25000.71\n",
      "Used Step: 6000000 | Mean ep 100 return:  314.66 | Used Time: 25067.55\n",
      "Used Step: 6016000 | Mean ep 100 return:  309.35 | Used Time: 25134.56\n",
      "Used Step: 6032000 | Mean ep 100 return:  297.95 | Used Time: 25201.68\n",
      "Used Step: 6048000 | Mean ep 100 return:  284.84 | Used Time: 25268.71\n",
      "Used Step: 6064000 | Mean ep 100 return:  285.02 | Used Time: 25335.6\n",
      "Used Step: 6080000 | Mean ep 100 return:  284.16 | Used Time: 25402.46\n",
      "Used Step: 6096000 | Mean ep 100 return:  287.41 | Used Time: 25469.88\n",
      "Used Step: 6112000 | Mean ep 100 return:  283.11 | Used Time: 25537.6\n",
      "Used Step: 6128000 | Mean ep 100 return:  281.78 | Used Time: 25605.56\n",
      "Used Step: 6144000 | Mean ep 100 return:  294.17 | Used Time: 25673.11\n",
      "Used Step: 6160000 | Mean ep 100 return:  302.26 | Used Time: 25740.94\n",
      "Used Step: 6176000 | Mean ep 100 return:  300.17 | Used Time: 25809.18\n",
      "Used Step: 6192000 | Mean ep 100 return:  293.61 | Used Time: 25876.74\n",
      "Used Step: 6208000 | Mean ep 100 return:  286.89 | Used Time: 25944.53\n",
      "Used Step: 6224000 | Mean ep 100 return:  287.48 | Used Time: 26012.3\n",
      "Used Step: 6240000 | Mean ep 100 return:  300.03 | Used Time: 26080.25\n",
      "Used Step: 6256000 | Mean ep 100 return:  305.94 | Used Time: 26148.05\n",
      "Used Step: 6272000 | Mean ep 100 return:  313.95 | Used Time: 26215.71\n",
      "Used Step: 6288000 | Mean ep 100 return:  306.96 | Used Time: 26283.39\n",
      "Used Step: 6304000 | Mean ep 100 return:  304.73 | Used Time: 26350.75\n",
      "Used Step: 6320000 | Mean ep 100 return:  307.25 | Used Time: 26418.01\n",
      "Used Step: 6336000 | Mean ep 100 return:  316.79 | Used Time: 26485.89\n",
      "Used Step: 6352000 | Mean ep 100 return:  318.39 | Used Time: 26553.55\n",
      "Used Step: 6368000 | Mean ep 100 return:  324.01 | Used Time: 26621.55\n",
      "Used Step: 6384000 | Mean ep 100 return:  327.52 | Used Time: 26689.67\n",
      "Used Step: 6400000 | Mean ep 100 return:  331.73 | Used Time: 26757.97\n",
      "Used Step: 6416000 | Mean ep 100 return:  338.83 | Used Time: 26825.66\n",
      "Used Step: 6432000 | Mean ep 100 return:  347.61 | Used Time: 26893.44\n",
      "Used Step: 6448000 | Mean ep 100 return:  352.97 | Used Time: 26961.39\n",
      "Used Step: 6464000 | Mean ep 100 return:  355.31 | Used Time: 27029.45\n",
      "Used Step: 6480000 | Mean ep 100 return:  359.06 | Used Time: 27097.39\n",
      "Used Step: 6496000 | Mean ep 100 return:  357.18 | Used Time: 27164.9\n",
      "Used Step: 6512000 | Mean ep 100 return:  355.83 | Used Time: 27232.69\n",
      "Used Step: 6528000 | Mean ep 100 return:  362.87 | Used Time: 27300.15\n",
      "Used Step: 6544000 | Mean ep 100 return:  369.22 | Used Time: 27367.32\n",
      "Used Step: 6560000 | Mean ep 100 return:  364.85 | Used Time: 27434.95\n",
      "Used Step: 6576000 | Mean ep 100 return:  364.89 | Used Time: 27501.99\n",
      "Used Step: 6592000 | Mean ep 100 return:  360.78 | Used Time: 27569.49\n",
      "Used Step: 6608000 | Mean ep 100 return:  352.52 | Used Time: 27637.75\n",
      "Used Step: 6624000 | Mean ep 100 return:  348.77 | Used Time: 27706.23\n",
      "Used Step: 6640000 | Mean ep 100 return:  347.83 | Used Time: 27774.67\n",
      "Used Step: 6656000 | Mean ep 100 return:  347.83 | Used Time: 27842.92\n",
      "Used Step: 6672000 | Mean ep 100 return:  348.86 | Used Time: 27910.46\n",
      "Used Step: 6688000 | Mean ep 100 return:  351.66 | Used Time: 27978.24\n",
      "Used Step: 6704000 | Mean ep 100 return:  356.58 | Used Time: 28045.99\n",
      "Used Step: 6720000 | Mean ep 100 return:  358.89 | Used Time: 28113.62\n",
      "Used Step: 6736000 | Mean ep 100 return:  362.56 | Used Time: 28181.31\n",
      "Used Step: 6752000 | Mean ep 100 return:  352.0 | Used Time: 28248.93\n",
      "Used Step: 6768000 | Mean ep 100 return:  348.52 | Used Time: 28316.76\n",
      "Used Step: 6784000 | Mean ep 100 return:  345.34 | Used Time: 28384.61\n",
      "Used Step: 6800000 | Mean ep 100 return:  347.2 | Used Time: 28452.52\n",
      "Used Step: 6816000 | Mean ep 100 return:  343.87 | Used Time: 28520.53\n",
      "Used Step: 6832000 | Mean ep 100 return:  344.88 | Used Time: 28588.36\n",
      "Used Step: 6848000 | Mean ep 100 return:  347.96 | Used Time: 28655.97\n",
      "Used Step: 6864000 | Mean ep 100 return:  346.97 | Used Time: 28723.32\n",
      "Used Step: 6880000 | Mean ep 100 return:  346.33 | Used Time: 28790.82\n",
      "Used Step: 6896000 | Mean ep 100 return:  349.45 | Used Time: 28858.17\n",
      "Used Step: 6912000 | Mean ep 100 return:  352.59 | Used Time: 28925.76\n",
      "Used Step: 6928000 | Mean ep 100 return:  347.13 | Used Time: 28993.26\n",
      "Used Step: 6944000 | Mean ep 100 return:  344.41 | Used Time: 29060.66\n",
      "Used Step: 6960000 | Mean ep 100 return:  350.05 | Used Time: 29127.98\n",
      "Used Step: 6976000 | Mean ep 100 return:  353.8 | Used Time: 29195.63\n",
      "Used Step: 6992000 | Mean ep 100 return:  354.77 | Used Time: 29262.75\n",
      "Used Step: 7008000 | Mean ep 100 return:  357.38 | Used Time: 29330.0\n",
      "Used Step: 7024000 | Mean ep 100 return:  358.93 | Used Time: 29397.47\n",
      "Used Step: 7040000 | Mean ep 100 return:  360.74 | Used Time: 29464.76\n",
      "Used Step: 7056000 | Mean ep 100 return:  348.88 | Used Time: 29531.94\n",
      "Used Step: 7072000 | Mean ep 100 return:  347.24 | Used Time: 29599.1\n",
      "Used Step: 7088000 | Mean ep 100 return:  346.81 | Used Time: 29666.34\n",
      "Used Step: 7104000 | Mean ep 100 return:  345.83 | Used Time: 29733.49\n",
      "Used Step: 7120000 | Mean ep 100 return:  341.81 | Used Time: 29800.63\n",
      "Used Step: 7136000 | Mean ep 100 return:  336.44 | Used Time: 29868.0\n",
      "Used Step: 7152000 | Mean ep 100 return:  327.52 | Used Time: 29935.19\n",
      "Used Step: 7168000 | Mean ep 100 return:  328.39 | Used Time: 30002.44\n",
      "Used Step: 7184000 | Mean ep 100 return:  327.81 | Used Time: 30069.54\n",
      "Used Step: 7200000 | Mean ep 100 return:  326.22 | Used Time: 30136.91\n",
      "Used Step: 7216000 | Mean ep 100 return:  333.78 | Used Time: 30204.09\n",
      "Used Step: 7232000 | Mean ep 100 return:  334.33 | Used Time: 30271.43\n",
      "Used Step: 7248000 | Mean ep 100 return:  333.21 | Used Time: 30338.74\n",
      "Used Step: 7264000 | Mean ep 100 return:  336.28 | Used Time: 30406.06\n",
      "Used Step: 7280000 | Mean ep 100 return:  342.49 | Used Time: 30473.31\n",
      "Used Step: 7296000 | Mean ep 100 return:  346.96 | Used Time: 30540.43\n",
      "Used Step: 7312000 | Mean ep 100 return:  346.93 | Used Time: 30607.68\n",
      "Used Step: 7328000 | Mean ep 100 return:  344.88 | Used Time: 30674.83\n",
      "Used Step: 7344000 | Mean ep 100 return:  353.49 | Used Time: 30742.07\n",
      "Used Step: 7360000 | Mean ep 100 return:  353.45 | Used Time: 30809.5\n",
      "Used Step: 7376000 | Mean ep 100 return:  354.79 | Used Time: 30876.83\n",
      "Used Step: 7392000 | Mean ep 100 return:  365.86 | Used Time: 30944.09\n",
      "Used Step: 7408000 | Mean ep 100 return:  367.2 | Used Time: 31011.31\n",
      "Used Step: 7424000 | Mean ep 100 return:  364.7 | Used Time: 31078.58\n",
      "Used Step: 7440000 | Mean ep 100 return:  366.74 | Used Time: 31145.68\n",
      "Used Step: 7456000 | Mean ep 100 return:  371.35 | Used Time: 31213.0\n",
      "Used Step: 7472000 | Mean ep 100 return:  363.48 | Used Time: 31280.36\n",
      "Used Step: 7488000 | Mean ep 100 return:  363.82 | Used Time: 31347.54\n",
      "Used Step: 7504000 | Mean ep 100 return:  359.21 | Used Time: 31414.82\n",
      "Used Step: 7520000 | Mean ep 100 return:  362.73 | Used Time: 31481.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Step: 7536000 | Mean ep 100 return:  360.46 | Used Time: 31549.12\n",
      "Used Step: 7552000 | Mean ep 100 return:  360.0 | Used Time: 31616.22\n",
      "Used Step: 7568000 | Mean ep 100 return:  365.88 | Used Time: 31683.44\n",
      "Used Step: 7584000 | Mean ep 100 return:  364.95 | Used Time: 31750.64\n",
      "Used Step: 7600000 | Mean ep 100 return:  347.71 | Used Time: 31818.17\n",
      "Used Step: 7616000 | Mean ep 100 return:  336.85 | Used Time: 31885.43\n",
      "Used Step: 7632000 | Mean ep 100 return:  334.08 | Used Time: 31953.38\n",
      "Used Step: 7648000 | Mean ep 100 return:  333.94 | Used Time: 32021.86\n",
      "Used Step: 7664000 | Mean ep 100 return:  331.1 | Used Time: 32090.26\n",
      "Used Step: 7680000 | Mean ep 100 return:  328.82 | Used Time: 32158.24\n",
      "Used Step: 7696000 | Mean ep 100 return:  332.19 | Used Time: 32225.64\n",
      "Used Step: 7712000 | Mean ep 100 return:  334.23 | Used Time: 32293.15\n",
      "Used Step: 7728000 | Mean ep 100 return:  331.04 | Used Time: 32360.51\n",
      "Used Step: 7744000 | Mean ep 100 return:  329.2 | Used Time: 32427.99\n",
      "Used Step: 7760000 | Mean ep 100 return:  323.59 | Used Time: 32495.44\n",
      "Used Step: 7776000 | Mean ep 100 return:  327.83 | Used Time: 32562.97\n",
      "Used Step: 7792000 | Mean ep 100 return:  327.15 | Used Time: 32630.47\n",
      "Used Step: 7808000 | Mean ep 100 return:  319.3 | Used Time: 32697.73\n",
      "Used Step: 7824000 | Mean ep 100 return:  327.99 | Used Time: 32765.09\n",
      "Used Step: 7840000 | Mean ep 100 return:  330.03 | Used Time: 32832.49\n",
      "Used Step: 7856000 | Mean ep 100 return:  343.76 | Used Time: 32899.87\n",
      "Used Step: 7872000 | Mean ep 100 return:  349.96 | Used Time: 32967.01\n",
      "Used Step: 7888000 | Mean ep 100 return:  354.36 | Used Time: 33034.27\n",
      "Used Step: 7904000 | Mean ep 100 return:  358.35 | Used Time: 33101.72\n",
      "Used Step: 7920000 | Mean ep 100 return:  360.53 | Used Time: 33169.11\n",
      "Used Step: 7936000 | Mean ep 100 return:  362.63 | Used Time: 33236.63\n",
      "Used Step: 7952000 | Mean ep 100 return:  361.02 | Used Time: 33304.12\n",
      "Used Step: 7968000 | Mean ep 100 return:  360.34 | Used Time: 33371.64\n",
      "Used Step: 7984000 | Mean ep 100 return:  366.84 | Used Time: 33439.09\n",
      "Used Step: 8000000 | Mean ep 100 return:  373.04 | Used Time: 33506.6\n",
      "Used Step: 8016000 | Mean ep 100 return:  372.61 | Used Time: 33573.94\n",
      "Used Step: 8032000 | Mean ep 100 return:  369.57 | Used Time: 33641.18\n",
      "Used Step: 8048000 | Mean ep 100 return:  362.57 | Used Time: 33708.43\n",
      "Used Step: 8064000 | Mean ep 100 return:  356.26 | Used Time: 33775.9\n",
      "Used Step: 8080000 | Mean ep 100 return:  351.36 | Used Time: 33843.08\n",
      "Used Step: 8096000 | Mean ep 100 return:  351.1 | Used Time: 33910.01\n",
      "Used Step: 8112000 | Mean ep 100 return:  349.75 | Used Time: 33977.08\n",
      "Used Step: 8128000 | Mean ep 100 return:  344.15 | Used Time: 34043.94\n",
      "Used Step: 8144000 | Mean ep 100 return:  333.63 | Used Time: 34111.03\n",
      "Used Step: 8160000 | Mean ep 100 return:  331.66 | Used Time: 34178.15\n",
      "Used Step: 8176000 | Mean ep 100 return:  326.6 | Used Time: 34245.2\n",
      "Used Step: 8192000 | Mean ep 100 return:  325.64 | Used Time: 34312.5\n",
      "Used Step: 8208000 | Mean ep 100 return:  323.55 | Used Time: 34379.96\n",
      "Used Step: 8224000 | Mean ep 100 return:  322.15 | Used Time: 34447.29\n",
      "Used Step: 8240000 | Mean ep 100 return:  318.98 | Used Time: 34514.51\n",
      "Used Step: 8256000 | Mean ep 100 return:  320.21 | Used Time: 34581.93\n",
      "Used Step: 8272000 | Mean ep 100 return:  320.13 | Used Time: 34649.2\n",
      "Used Step: 8288000 | Mean ep 100 return:  315.51 | Used Time: 34716.4\n",
      "Used Step: 8304000 | Mean ep 100 return:  320.3 | Used Time: 34783.61\n",
      "Used Step: 8320000 | Mean ep 100 return:  323.63 | Used Time: 34850.98\n",
      "Used Step: 8336000 | Mean ep 100 return:  322.91 | Used Time: 34918.18\n",
      "Used Step: 8352000 | Mean ep 100 return:  330.98 | Used Time: 34985.41\n",
      "Used Step: 8368000 | Mean ep 100 return:  333.6 | Used Time: 35052.52\n",
      "Used Step: 8384000 | Mean ep 100 return:  339.32 | Used Time: 35119.68\n",
      "Used Step: 8400000 | Mean ep 100 return:  343.58 | Used Time: 35186.89\n",
      "Used Step: 8416000 | Mean ep 100 return:  354.36 | Used Time: 35254.07\n",
      "Used Step: 8432000 | Mean ep 100 return:  358.44 | Used Time: 35321.26\n",
      "Used Step: 8448000 | Mean ep 100 return:  361.82 | Used Time: 35388.54\n",
      "Used Step: 8464000 | Mean ep 100 return:  368.34 | Used Time: 35455.87\n",
      "Used Step: 8480000 | Mean ep 100 return:  371.05 | Used Time: 35523.06\n",
      "Used Step: 8496000 | Mean ep 100 return:  378.92 | Used Time: 35590.37\n",
      "Used Step: 8512000 | Mean ep 100 return:  382.49 | Used Time: 35657.56\n",
      "Used Step: 8528000 | Mean ep 100 return:  391.35 | Used Time: 35724.72\n",
      "Used Step: 8544000 | Mean ep 100 return:  394.18 | Used Time: 35791.83\n",
      "Used Step: 8560000 | Mean ep 100 return:  393.69 | Used Time: 35859.1\n",
      "Used Step: 8576000 | Mean ep 100 return:  394.71 | Used Time: 35926.42\n",
      "Used Step: 8592000 | Mean ep 100 return:  393.71 | Used Time: 35993.62\n",
      "Used Step: 8608000 | Mean ep 100 return:  390.23 | Used Time: 36060.95\n",
      "Used Step: 8624000 | Mean ep 100 return:  385.84 | Used Time: 36128.19\n",
      "Used Step: 8640000 | Mean ep 100 return:  380.45 | Used Time: 36195.52\n",
      "Used Step: 8656000 | Mean ep 100 return:  369.41 | Used Time: 36263.43\n",
      "Used Step: 8672000 | Mean ep 100 return:  366.4 | Used Time: 36331.16\n",
      "Used Step: 8688000 | Mean ep 100 return:  363.33 | Used Time: 36398.84\n",
      "Used Step: 8704000 | Mean ep 100 return:  361.07 | Used Time: 36466.55\n",
      "Used Step: 8720000 | Mean ep 100 return:  357.43 | Used Time: 36534.17\n",
      "Used Step: 8736000 | Mean ep 100 return:  342.52 | Used Time: 36602.02\n",
      "Used Step: 8752000 | Mean ep 100 return:  337.27 | Used Time: 36669.99\n",
      "Used Step: 8768000 | Mean ep 100 return:  330.68 | Used Time: 36737.81\n",
      "Used Step: 8784000 | Mean ep 100 return:  332.14 | Used Time: 36805.48\n",
      "Used Step: 8800000 | Mean ep 100 return:  331.4 | Used Time: 36873.14\n",
      "Used Step: 8816000 | Mean ep 100 return:  330.95 | Used Time: 36940.77\n",
      "Used Step: 8832000 | Mean ep 100 return:  329.14 | Used Time: 37008.13\n",
      "Used Step: 8848000 | Mean ep 100 return:  323.27 | Used Time: 37075.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ffa7416f17dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mLEARN_START\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mLEARN_FREQ\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-950126e561d8>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# forward calc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0msil_action_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msil_b_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0msil_action_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msil_action_log_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0msil_cur_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msil_b_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-10c67aca7c7d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# x is a tensor of (m, 4, 84, 84)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# x.size(0) : mini-batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sac = SSAC()\n",
    "\n",
    "# model load with check\n",
    "if LOAD and os.path.isfile(PRED_PATH) and os.path.isfile(TARGET_PATH):\n",
    "    sac.load_model()\n",
    "    pkl_file = open(RESULT_PATH,'rb')\n",
    "    result = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    print('Load complete!')\n",
    "else:\n",
    "    result = []\n",
    "    print('Initialize results!')\n",
    "\n",
    "print('Collecting experience...')\n",
    "\n",
    "# episode step for accumulate reward \n",
    "epinfobuf = deque(maxlen=100)\n",
    "# check learning time\n",
    "start_time = time.time()\n",
    "\n",
    "# env reset\n",
    "s = np.array(env.reset())\n",
    "\n",
    "for step in tqdm_notebook(range(1, N_STEP//N_ENVS + 1)):\n",
    "    \n",
    "    a = sac.choose_action(s)\n",
    "    \n",
    "    # take action and get next state\n",
    "    s_, r, done, infos = env.step(a)\n",
    "    s_ = np.array(s_)\n",
    "    \n",
    "    # log arrange\n",
    "    for info in infos:\n",
    "        maybeepinfo = info.get('episode')\n",
    "        if maybeepinfo: epinfobuf.append(maybeepinfo)\n",
    "            \n",
    "    # store transition\n",
    "    sac.sil_store_transition(s,a,r,done)\n",
    "    for i in range(len(s_)):\n",
    "        sac.store_transition(s[i],a[i],r[i],s_[i], done[i])\n",
    "        \n",
    "    if (step >= LEARN_START) and (step % LEARN_FREQ == 0):\n",
    "        sac.learn()\n",
    "        \n",
    "    s = s_\n",
    "            \n",
    "    if step % LOG_FREQ == 0:\n",
    "        # print log and save\n",
    "        # check time interval\n",
    "        time_interval = round(time.time() - start_time, 2)\n",
    "        # calc mean return\n",
    "        mean_100_ep_return = round(np.mean([epinfo['r'] for epinfo in epinfobuf]),2)\n",
    "        result.append(mean_100_ep_return)\n",
    "        # print epi log\n",
    "        print('Used Step:',sac.memory_counter,\n",
    "              '| Mean ep 100 return: ', mean_100_ep_return,\n",
    "              '| Used Time:',time_interval)\n",
    "        # save model\n",
    "        if SAVE:\n",
    "            sac.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(result)), result)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "        \n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=5)\n",
    "    anim.save('./ssac_breakout_result.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/sungyubkim/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.uint8'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward : 362.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9a1b3deec6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Reward : %.2f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdisplay_frames_as_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-05f42a91f360>\u001b[0m in \u001b[0;36mdisplay_frames_as_gif\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0manim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuncAnimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ssac_breakout_result.gif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagemagick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                         \u001b[0;31m# TODO: See if turning off blit is really necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                         \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_next_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0;31m# Reconnect signal for first draw if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;34m'''Finish any processing for writing the movie.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;34m'''Clean-up and collect the process used to write the movie file.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_sink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MovieWriter -- Command stdout:\\n%s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1673\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAD+CAYAAACgNTAxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABFNJREFUeJzt3TGOE2cYgGEmokY5QQ6QKiXaksoFZ0A5AA1bcoCUW+UAiCInoLAoKBFlKo5BFaVIkaGNknhmvfPaM8bP046xP1t6+fAPswzjOD4Clvtu7QHgWyEmiIgJImKCiJggIiaIiAkiYoKImCDyeO0BDhmGwT/NYHPGcRwOXbOZICImiIgJIpv9zrRFd3d3R/+a29vbyef49/VTzPGQ1zhW8b4ufQabCSI20xHu8zvdQ7ZXPcc5ZuC/bCaI2EwLFBtg7jn+bwvZPNtkM0HEZlqg2Bpzp30PnYPzs5kgYjMd4RTfVdb63kXPZoKImCAybPWHULoFgy1yCwacwWYPIPzFJJfGZoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCCy2Vsw5vi5BpzCklt/bCaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigsjF/v9MW/Dx5c3sY25+/XiGSdY391lcw+dgM0FETBARE0TEBBExQURMEHE0vsCXJ3+uPULi3eufZh/z/JffJ69fw9H3HJsJImKCiJggIiaIiAkiTvMmvH374+T1L4/+Wn2Gwn3ex9wcL158XjTDOd7n0hnn2EwQERNExAQRMUFETBBxmjdh7vRn92Y3+xy7Nz9MXt//vF80w33mmHuNLfjt7+nPqeE0Dy6CmCAiJoiICSJigojTvAXOcUr2bPfpHnM8PflrfNgve405l3DiOMdmgoiYICImiIgJImKCiJgg4mh84059JH2u17gGNhNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExASRx2sPcMi77/9Ye4Rvxqfd7qjHP93vTzTJ9t28fz/9gFevDl6ymSAiJoiICSKb/c5E55q/A52TzQQRmwn+YW6LjxPXhnGcuryeYRi2ORhXbRzH4dA1f8yDiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggstlbMODS2EwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNExAQRMUFETBARE0TEBBExQURMEBETRMQEETFBREwQERNEvgK66IXgzUTWJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = wrap(gym.make('BreakoutNoFrameskip-v4'))\n",
    "s = np.array(env.reset())\n",
    "total_reward = 0\n",
    "frames = []\n",
    "done_stack = 0\n",
    "\n",
    "for t in range(10000):\n",
    "    # Render into buffer. \n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    a = sac.choose_action(np.expand_dims(s,axis=0))\n",
    "    # take action and get next state\n",
    "    s_, r, done, info = env.step(a)\n",
    "    s_ = np.array(s_)\n",
    "    total_reward += r\n",
    "    if done:\n",
    "        done_stack += 1\n",
    "        if done_stack == 5:\n",
    "            break\n",
    "    s = s_\n",
    "env.close()\n",
    "print('Total Reward : %.2f'%total_reward)\n",
    "display_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./ssac_pong_result.gif \"segment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
